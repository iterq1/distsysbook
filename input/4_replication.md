# %chapter_number%. Репликация

Проблема репликации одна из многих проблем в распределенных системах. Мы фокусируемся на этой проблеме среди других, таких как выбор лидера(мастер-реплики), определение отказов, взаимоисключения доступа(mutual exclusion), консенсус и глобальные снэпшоты(снимки состояния), потому что зачастую эта проблема интересует большинство людей. Например чтобы иметь возможность различать базы данных по описанию их возможностей в терминах репликации. Кроме того, репликация дает контекст для многих под-проблем таких как выбор лидера, определения отказов, консенсуса и атомарной посылке сообщщений всем узлам сети(броадкастинг).

Репликация это группа связанных проблем. Какие механизмы и шаблоны коммуникации предоставять нам такие показатели производительности и доступности которые нам нужны? Как мы можем предоставлять отказоустойчивость, надежность и отсутсвие расходений сталкиваясь с разделениями сети и одновременными падениями узлом?

Опять таки существует много подходов к репликации. Под подходом здесь понимается просто высокоуровневый шаблон применимый для систем с репликацией. Такой взгляд помогает фокусироватся на общей картине, а не конкретных деталях. Наша цель здесь исследовать простанство возможных дизайнов, а не разобратся с спецификой конкретных алгоритмов.

Для начала дадим определение репликации в общих чертах. Мы предполагаем что мы имеем некотрую базу данных в начальном состоянии, и могут совершать запросы которые изменяют состояние базы данных.

<img src="images/replication-both.png" alt="replication" style="height: 340px;">

Тогда механизм и шаблон коммуникации могут быть разделены на несколько стадий:

1. (Запрос) Клиент посылает запрос на сервер
3. (Синхронная часть) Происходит синхронная часть алгоритма репликации
4. (Результат) Клиенту возврашается ответ
5. (Асинхронная часть) Происходит асинхронная часть репликации

Это стадии выделены по мотивам [этой статьи](https://www.google.com/search?q=understanding+replication+in+databases+and+distributed+systems). Заметим, что модель сообщений которыми обмениваются отдельные части системы в каждой стадии зависит от конкретного алгоритма: попытаемся обойтись без обсуждения конкретных алгоритмов.

Учитывая эти этапы, какие шаблоны коммуникации мы можем создать? И какие неочевидные последствия будут у нашего выбора для производительности и доступности?

## Синхронная репликация

Первый паттерн это синхронная репликация(также известная как активная, или интенсивная или пуш-репликация, или пессимистическая репликация). Давайте изобразим это:

<img src="images/replication-sync.png" alt="replication" style="height: 340px;">

Здесь, мы можем увидеть три различных стадии: первая, клиент отправляет запрос. Следующая, когда выполняется синхронная часть репликации. Во время этой стадии клиент блокируется - ожидая ответ от системы.

Во время синхронной фазы, первый сервер контактирует со вторым и ждет пока он не получит ответы от всех остальных серверов. В конце, он отсылает ответ клиенту информирующий его об успехе или неудачи.

Это выглядит довольно просто. Что мы можем сказать о специфичных соглашениях о шаблонах коммуникации, не погружаясь в детали конкретного алгоритма синхронной фазы? Во-первых, заметим что запись осуществляется при помощи N - из - N подхода: прежде чем результат будет возврашен, он должен быть доставлен и признан корректным каждым сервером в системе(если серверов N то запись должна быть потверждена N раз).

С точки зрения производительности это означает, что система будет быстрой настолько же как и самая медленная машина в кластере. Система также будет крайне чувствительна к изменениям сетевых задержек, так как необходимо дождатся пока ответа каждого сервера прежде чем ответить клиенту.

Использующая данный подход(N-из-N) система не может быть устойчива к выходу из строя какого либо сервера. При падении сервера, система на долгое время теряет возможность продолжать запись на всех узлах и соотвественно не может продолжать обрабатывать запросы клиента. Она все еще может предоставлять доступ к данным на чтение, но их модификация становится не возможно при падении узла при такой архитектуре.

Такое механизм работы позволяет предоставлять строгие гарантии надежности: клиент может быть уверен что все N серверов получили, сохранили и согласились с запросом на модификацию, когда клиент получил ответ. Чтобы потерять принятое обновление необходимо чтобы его потеряли все N серверов, что является настолько хорошей гарантией насколько мы можем дать.

## Асинхронная репликация

Давайте сравним данные подход с другим паттерном - асинхронной репликацией (a.k.a. пассивная репликация, или pull-репликация, или ленивая репликация). Как вы можете догадатся, этот подход противоположен синхронной репликации:

<img src="images/replication-async.png" alt="replication" style="height: 340px;">

Здесь, мастер (/ лидер / координатор) немедленно возврашает ответ клиенту. Максимум что он делает это сохраняет изменения локально, но он не будет делать какую либо синхронную отсылку этих изменений другим серверам и не будет заставлять ждать клиента пока произойдет коммуникация с другими серверами.

После этого, наступает стадия в который выполняется асинхронная часть механизма репликации. Во время нее, мастер сообщает другим серверам обновить локальную версию данных. Детали этого зависят от алгоритма используемого для репликации.

Что мы можем сказать о специфики такого подхода без углубления в детали конкретных алгоритмов? Что ж, это запись 1 - из - N: результат будет возврашен немедленно, а обновления будут распространены немного позже.

С точки зрения производительности это означает что система будет быстрой: клиенту нет нужды тратить время ожидая пока система совершит всю внутреннюю работу. Такая система также более невосприимчива к сетевым задержкам, так как изменения задержек внутри системы не вызывают увеличение времени ожидания клиента.

Такой механизм может предоставлять только слабые или вероятностные гарантии надежности. Если не случится ничего неправильного, тогда данные в конечном итоге будут реплицированны на все N машин. Однако, если только сервер содержаший данные потеряет их прежде чем это случится тогда мы можем потерять эти данные навсегда.

Данный подход, позволяет системе оставатся доступной до тех пор пока остается хотя бы один узел(это только в теории - на практике нагрузка на него будет слишком высока). Полностью "ленивый" подход не предоставляет гарантий надежности и согласованности; вы можете писать данные в систему, но нет никаких гарантий что вы сможете прочитать те данные что вы записали в случае возникновения каких либо ошибок.

В конце концов, следует заметить что пассивная репликация не может обеспечивать одинаковое состояние на всех узлах. Если вы проводите запись в нескольких узлах и не требуете чтобы все узлы были синхронно согласны на запись, вы рискуете получить расхождение данных: чтение может возврашать разные данные из разных источников(в частности для узлов после востановления), и глобальные ограничения(которые требуют коммуникации всех узлов) не могут использоватся при таком подходе.

Детали коммуникации при чтении данных не упомянуты специально, потому что то как вы читаете данные напрямую зависит от способа записи: во время чтения вы хотите контактировать с несколькими узлами - если это представляется возможным. Немного более подробно об этом будет сказано в контексте кворумов.

Мы только обсудили два базовых подхода и не вдавались в детали специфики  конкретных алгоритмов. Еще мы смогли выяснить совсем немного о возможных моделях коммуникации а также их производительности, гарантиях надежности и доступности.

## Обзор большинства способов репликации

У нас была дискуссия о двух главных способах: синхронной и асинхронной репликации, а теперь давайте взглянем на большинство алгоритмов репликации.

Существует очень много различных способов разбить на категории техники применяемые для репликации. Второе разделение(после синхронной и асинхронной) которое мы обсудим, это разделение между:

- Методами репликации которые предотвращают расхождение ("single copy" системы) и
- Методами репликации которые могут приводит к расхождениям (мульти-мастер системы)

Первая группа методов удовлетворяет условиям "поведения аналогичного для не распределенной системы".  В частности, когда отказываает часть системы, гарантируется что только одная копия системы остается активной. Кроме того, система гарантирует что реплики всегда находятся в согласии. Это известно как проблема консенсуса.

Несколько процессов(или компьютеров) достигают консенсуса если все они согласны насчет некотрого значения. Более формально:

1. Соглашение: Каждый корректный процесс должен быть согласен с одним и тем же значением что и другие.
2. Целостность: Каждый корректный процесс может выбрать не более одного значения, и если он выбирает некотрое значение то оно должно быть предложено некотрым процессом.
3. Завершение: Все процессы должны в конечном счете принять решение.
4. Обоснованность: Если все корректные процессы предлагают значение V, тогда все корректные процессы должны принять значение V.

Конкурентный доступ к данным, выбор лидера, атомарная отсылка сообщей всем(броадкаст) или нескольким(мультикаст) узлам - все это частный случаи более общей проблемы консенсуса. Системы репликации которые поддерживат консистетность уровня "одна активная копия"("single-copy")  нуждаются в решении проблемы консенсуса каким либо способом.

Алгоритмы репликации которые поддерживают single-copy согласованность включают в себя следующие категории:

- 1n сообщений (асинхронный primary/backup)
- 2n сообщейний (синхронный primary/backup)
- 4n сообщений (2-ухфазный коммит, Мульти-Паксос)
- 6n сообщений (3-хфазный коммит, Паксос с повторящимся выбором лидера)

Эти алгоритмы отличаются по устойчивости к отказам (то есть типам отказов которые они могут обрабатывать). Классификация выше делит их просто по числу сообщений которые им надо отправить во время выполнения алгоритма, потому что, мне кажется интересно найти ответ на вопрос "Что мы получаем с увеличением обмена сообщениями?"

Диаграмма ниже адаптированная из работы Ryan Barret из [Google](http://www.google.com/events/io/2009/sessions/TransactionsAcrossDatacenters.html), описывает некотрые аспекты возможных вариантов опций:

![Сравнение методов репликации из http://www.google.com/events/io/2009/sessions/TransactionsAcrossDatacenters.html](images/google-transact09.png)

Характеристики согласованности, задержек, пропускной способности, возможности потери данных и способности к востановлению на диаграмме выше могут быть вытекают из сути двух главных методов репликации: синхронная репликация(во время который мы ждем прежде ответить) и асинхронной. Когда мы ждем, мы получаем хуже производительность но выше гарантии надежности. Разница в пропускной способности между 2PC  системах и основанных на кворуме системах станет очевидной когда мы будем обсуждать устойчивость к разделению(и задержкам).


На диаграмме, алгоритмы обеспечивающие слабую согласованность("согласованность в конечном итоге") объединены в одну категорию ("gossip"). Однако, мы будем обсуждать методы репликации с слабой согласованностью - gossip и системы с частичным кворумом - более детально. Строчка с заголовков "transactions" на самом деле ссылается больше на вычисление ограничений в рамках всей системы,  которые не поддерживаются в системах с слабой согласованность (хотя локальные ограничения и условия поддерживаются).

Следует отметить что системы предоставляющие гарантии только слабой согласованности требуют менее общих(более специальных) алгоритмов, и многие техники применимы к ним только частично. Системы не связывающие себя обязательством согласованности с единственной активной копией свободны от ограничения, что они должны работать "как на одной машине", их задачи менее очевидны, что в свою очередь позволяет людям сфокусироватся на том чтобы рассуждать о характеристиках которые имеет такая система.

Для примера:

- Клиент-ориентированная согласованность пытается предоставлять более понятные гарантии согласованности при возможных расхождениях данных.
- CRDTs (сходящиеся и коммутативные реплицируемые типы данных) используют  свойства полукольца (ассоциативность, коммутативность, имподентность) опредленных для структур данных основанных на состоянии и операциях.
- Анализ слияний(Confluence analysis) (как в Bloom language) использует информацию о монотонности вычислений максимально используя отсуствия порядка.
- PBS (вероятностные ограничения устаревания - probabilistically bounded staleness) использует симуляцию  и информацию с реальной системы чтобы характеризовать ожидаемое поведение системы с частичным кворумом.

Мы будем обсуждать все эти техники немного позже; для начала давайте посмотрим на алгоритмы репликации которые поддерживают согласованность во всей системе на уровне одной активной копии не допускающей расхождений(single-copy).

## Primary/backup репликация

Primary/backup репликация (также известная как репликация методом копирования мастера, мастер-слейв репликация и рпеликация отправкой логов) возможно наиболее общий из алгоритмов репликации, и самый простой. Все изменения выполненые на главной реплике и лог всех операций (или всех изменений) отправляется по сети остальным репликам. Как мы помним, возможны два варианта:

- изменения отсылаются асинхронно и
- изменения отсылаются синхронно

Синхронный вариант требует два сообщения ("обновление" + "подтверждение получения") в то время как асинхронный вариант только лишь "обновления".

P/B очень общий алгоритм. Для примера, по умолчанию MySQL репликация использует его асинхронный вариант. MongoDB также использует P/B (с некотрыми дополнениями для востанновления в случе отказа мастера). Все операции выполняются на одном мастер сервере, которые затем упорядочиваются в локальный лог и затем асинхронно воспроизводятся на резервной реплике.

Как мы обсуждали раньше в контексте асинхронной репликации, любая подобный алгоритм может предоставить только слабые гарантии надежности. В MySQL репликации это известно как лаг репликации: асинхронное копирование всегда отстает по крайне мере на одну операцию от мастера. Если мастер упадет, когда обновления еще не будут доставлены они будут потеряны.

Синхронный вариант primary/backup репликации обеспечивает сохранение записи на реплике прежде чем результат будет возвращен клиенту - ценой этому будет ожидание ответа всех реплик. Однако, стоит заметить что даже такой вариант может быть предоставлять только слабые гарантии. Рассмотрим следующий сценарий отказа:

- мастер принимает запись и отправляет ее на реплики
- реплики сохраняют ее и сообщают о успешной записи
- и в этот момент мастер падает прежде чем отправляет ответ клиенту

Клиент допускает что запись была не успешна, но реплики совершили запись; если реплика будет выдвинута на роль мастера, эта запись будет некорректна с точки зрения клиента. Может понадобится ручная очистка для синхронизации расходящихся мастера и реплики.

Данный сценарий конечно намеренно упрощен. Все алгоритмы мастер-слейв репликации следуют одним паттернам коммуникации но они отличаются в способности обработке востанновления после отказа, возможности реплики находится в оффлайне длительное время и так далее. Однако, не возможно быть полностью устойчивым к неудачным падениям мастера в такой схеме.

Ключевым в механизмах основанных на мастер-слейв алгоритмах является то что они предлагают гарантии настолько хорошие насколько это возможно(например они могут терять обновления или наоборот получать некорректные апдейты если узел падает в неподходящий момент). Более того, мастер-слейв конфигурации уязвимы к так называемому "split-brain", когда востановление путем выдвижение в качестве мастер сервера одной из реплик после проблем с сетью приводит к тому что некотрое время оказывается активным оба мастера(новый созданный из реплики и старый вернувшийся в строй).

Для предотвращения сбоя в неподходящий момент мы должны добавить еще один раунд обмена сообщениями, прийдя тем самым к протоколу двух-фазного коммита.

## Двух-фазный коммит (2PC)

[Двух-фазный коммит](http://en.wikipedia.org/wiki/Two-phase_commit_protocol) (2PC) это протокол используемый во многих классических реляционных базах данных. Для примера, MySQL Cluster (не путать с обычным MySQL) предоставляет синхронную репликацию используя 2PC. Диаграмма ниже иллюстрирует поток сообщений:

    [ Координатор ] -> Готовы к совершению операции(commit)?     [ Узлы ]
                    <- Да / Нет

    [ Координатор ] -> Завершить / откатить [ Узлы ]
                    <- Результат операции

В первой фазе(голосования),  координатор отсылает обновления всем участникам. Каждый участвующий процесс исполняет обновления и голосует завершить операции или откатить. Когда голосуют за завершение участники сохраняют обновление в некотрой временной зоне (write-ahead лог). Пока выполняется вторая фаза обновления считаются временными.

Во второй фазе(решения), координатор подводит итог на основе данных с реплик и сообщает каждому участнику. Если все участники голосовали за совершение операции, тогда обновление перемещается из временной зоны в место постоянного хранения.

Наличие второй фазы перед сохранением в постоянное хранилище крайне полезно, так как оно позволяет системе откатится в случае если узел упадет.  В отличии от 2PC в мастер-слейв схеме, которая не содержит шага для отмены операции в случае если операция была успешно выполнена на одних узлах а на других случился отказ и следовательно реплики оказались подвержены расхождениям.

2PC склонен к блокировкам, пока один узел отказал (участник или координатор) все операции блокируетются пока узел не востановится. Востановление зачастую возможно благодаря второй фазе, во время которой другие узлы информируют о состоянии системы. Заметим что 2PC допускает что данные в поостоянном хранилище никогда не будут потеряны и узлы никогда не откажут навсегда. Потери данных остаются возможными если данные в постоянном хранилище будут повреждены при падении.

Детали процедуры востановления после сбоев узлов довольно сложны и мы не будем вдаватся в специфику. Главные задачи это обеспечить надежную запись на диск(например записывать все на диск не кэшируя) и The major tasks are ensuring that writes to disk are durable (e.g. flushed to disk rather than cached) и убедиться, что были приняты правильные решения для востанновления (например изучив исход раунда востановить или отменить локальные изменения).

Как мы узнали в главе посвященной CAP теореме, 2PC это CA - он не устойчив к разделению. Модель отказов 2PC не включает в себя разделения сети; предписанный им способ востановится после отказа узла это подождать пока не востановится сеть. То есть несуществует безопасного способа выдвинуть нового координатора если один упал; необходимо ручное воздействие. 2PC также довольно чувствителен к задержкам, так как это N-из-N подход к записи когда запись не может продолжатся пока самый медленный узел не подтвердит ее.

2PC это достойный компромисс между производительностью и отказоустойчивостью, поэтому он так популярен в классических реляционных базах данных. Однако, более новые системы зачастую используют алгоритмы консенсуса устойчивые к разделению, поскольку такой алгоритм может обсепечить востанновление при временных разделениях сети, а также меньшую чувствительность к задержкам между узлами.

Давайте взглянем на алгоритмы консенсуса устойчивые к разделению.

## Алгоритмы консенсуса устойчивые к разделению

Алгоритмы консенсуса устойчивые к разделению ушли насколько это возможно далеко от устойчивых к отказам алгоритмов представляющих консистентность без расхождений. Следующий класс алгоритмов устойчивым к отказам: алгоритмы устойчивые к [произвольным (Византийским) отказам](http://en.wikipedia.org/wiki/Byzantine_fault_tolerance); они включают в себя отказы проявляющиеся в некорректном поведении узлов. Такие алгоритмы редко используются в коммерческих системах, потому что они более дорогие и сложные для реализации и запуска - и следовательно мы не будем обсуждать их.

Когда обсуждение доходит до алгоритмов консенсуса устойчивых к разделениям, многие вспоминают широко известный алгоритм Paxos. Однако общеизвестно что он довольно сложен для реализации и обьяснения, так что мы сфокусируемся на Raft, не так давно созданым алгоритмом(начало 2013) с целью быть более простым в понимании и реализации. Давайте сперва взглянем на сетевое разделение и главные характеристики алгоритмов консенсуса устойчивых к разделениям.

### Что такое сетевое разделение?

Сетевое разделение это исчезновение связи по сети к одному или нескольким узлами. Узлы при этом остаются активны и даже могут обслуживать запросы клиентов на своей стороне сетевого раздела. Как мы узнали раньше - во время дискуссии о CAP теореме - сетевые разделения происходят и не все системы могут полноценно обрабатывать их.

Разделения сети коварны потому что во время сетевого разделения не возможно различать упавший узел от узла который отделен от остальных упашей сетью. Если происходит сетевое разделение, и при этом все узлы активны, тогда система разделяется на две партиции которые одновременно активн. 2 диаграммы ниже иллюстрируют как сетевое разделение может быть похожим на падение узла.

Система с 2 узлами, при падении узла и при разделении сети:

<img src="images/system-of-2.png" alt="replication" style="max-height: 100px;">

Система с 3 узлами, при падении узла и при разделении сети:

<img src="images/system-of-3.png" alt="replication"  style="max-height: 130px;">

Система обеспечивающая согласованность без расхождений должна иметь способ отличать такие ситуации: иначе она будет разбита на две одинаковые системы которые могут расходится и система перестанет поддерживать иллюзию работы в единственном экземпляре.

Устойчивость к сетевым разделениям для систем обеспечивающих согласованность без расхождений, требует чтобы во время сетевого разделения только одна часть системы была активной, так как работе разделенной системе не возможно предотвратить расхождения(вспоминаем CAP теорему).

### Решения основанные на большинстве

Поэтому алгоритмы консенсуса устойчивые к разделению основаны на голосе большинства. Требование большинства узлов - в отличии от всех узлов (как в 2PC) - для согласия на обновление позволяет меньшинству узлов быть упавшими недоступными изза разделения сети или очень медленными. Пока `(N/2 + 1)-из-N` узлов работоспобны и доступны система может продолжать работу.

Алгоритмы консенсуса устойчивые к разделению используют нечетное числов узлов (например, 3, 5 или 7). Используя только 2 узла невозможно определить абсолютное большинство. Для примера, если у нас 3 узла, тогда система устойчива к отказу одного узла, если узлов 5 - тогда уже к падению двух.

Когда происходит разделение сети, партиции ведут себя асимметрично. Одна будет содержать большинство узлов. Меньшинство прекратит обрабатывать операции чтобы предотвратить расхождения пока сеть не востанновится, но партиция с большинством участников останется активной. Это обеспечивает единственную копию системы которая остается активной.

Большинство также полезно потому что оно устойчиво к несогласию узлов: если есть искажения или отказы, тогда узлы могут проголосовать по-разному. Однако, поскольку может быть только одно решение принятое большинством, временное несогласие может заблокировать принятие окончательного решения(отказ от свойства живучести) но не может нарушить критерий целостности "единой копии" (свойство корректности).

### Роли

Существует два способа выстраивать систему: либо все узлы имеют одни и теже обязанности, либо разные узлы могут иметь разные роли.

Алгоритмы консенсуса для репликации как правило разделяют роли между узлами. Наличие одного зафиксированного лидера или мастер-сервера это оптимизация которая делает системы более эффективной, так как мы знаем, что все обновления должны пройти через этот сервер. Узлы которые не являются лидером должны передавать запросы, пришедшие к ним, лидеру.

Заметим что наличие различных ролей не исключает востановления системы после отказа лидера(или другого узла). То что роли закреплены за узлами не означает, что при востановлении после сбоя может произойти переназначение ролей(например при помощи фазы выдвижения лидера). Узлы могу повторно использовать результат выбора лидера повторно пока не произойдет новый сбой узлов или сетевой раздел.

И Paxos и Raft используют разные роли для разных узлов. Обычно, они определяют лидера(предлагающий узел ("proposer") в Paxos) который отвечает за координацию во время нормальной работы системы. Во это время остальные узлы это "последователи"(followers) (принимающие ("acceptors") или голосующие("voters") узлы в Paxos).

### Эпохи

Каждый период нормального выполнения операции и в Paxos и в Raft называется эпохой("epoch") ("term" в Raft).  Во время каждой эпохи только один узел назначен лидером(похожая система [используется в Японии](http://en.wikipedia.org/wiki/Japanese_era_name) где названия эпох сменяется вместе со сменой императоров).

<img src="images/epoch.png" alt="replication"  style="max-height: 130px;">

После успешного выбора, лидер будет координировать систему пока не кончится эпоха. Как показано на диаграмме выше(из публикации о Raft), некотрые выборы лидера могут неудастся, что вызовет немедленный конец эпохи.

Эпохи работают как логические часы позволяющие узлам определить когда узлы с устаревшими данными начинают сообщатся с ними - узлы бывшие в отделенной части или были выведены из эксплутуации будут иметь меньший номер эпохи чем текущее значение эпохи работающих узлов, соотвественно команды устаревших узлов будут игнорироватся.

### Смена лидера при помощи дуэли

Во время нормальной операции, алгоритм консенсуса устойчивый к разделению довольно прост. Как мы увидели раньше, если мы не беспокоимся об устойчивости мы можем просто использовать 2PC. Более сложным является обеспечение условия что как только решение путем консенсуса было принято оно не будет потеряно и протокол сможет корректно обрабатывать смену лидера в результате сетевого сбоя или падения узла.

Все узлы начинают как ведомые(followers); один узел выбирается в лидеры на старте. Во время нормальной работы систем, лидер поддерживает индикатор своего состояния("heartbeat") который позволяет ведомым узлам определить когда лидер упал или оказался отделенным.

Когда узел определяет что лидер неотвечает(или в случае старта работы системы - лидера просто нету), он переключается в промежуточное состояние ("кандидата" в Raft) в котором он увеличивает счетчик эпохи на один, иницирует выборы лидера и соревнуется за то чтобы стать лидером с другими кандидатами.

Для того чтобы быть избранным лидером, узел должен получить большинство голосов. Один способ это присвоить голоса простым присвоением их по приниципу "первым прибыл - первым получил; в этом способе лидер будет выбран в конечном итоге. Добавление случайного количества времени ожидания между попытками узлов быть конкурировать за место лидера будут сокращать число узлов которые вытаются быть выбранными одновременнно.

### Номерованные предложения в пределах эпохи

Во время каждой эпохи лидер предлагает одно значение для голосования в один момент времени. В пределах эпохи каждое предложение нумеруется уникальным возрастающим числом. Ведомые(избирающие / акцепторы) принимают первое предложение с определенным номером предположения.

### Нормальное проведение операций

Во время нормальной операции, все предложения проходят через лидера. Когда клиент отправляет предложение(например иницирует операцию обновления), лидер контактирует со всеми узлами объединяя их в кворум. Если нет конкурирующих предложений (на основе полученных ответов от ведомых узлов), лидер предлагает значение. Если большинство узлов принимают значение, следовательно данное значение считается принятым.

Так как возможно, что другой узел также возможно пытается выступать в качестве лидера, мы должны гарантировать что конгда одно предложение было принято, его значение никогда не будет изменено. Иначе предложение которое уже было принято может быть к примеру отменено конкурирующим лидером. Лэмпорт говорит об этом так:

> P2: Если предложение со значением `v` было выбрано, тогда каждое предложение с большим номером должно предполагать что выбранное значение содержит `v`.

Для того чтобы это свойство было удовлетворено требуется чтобы и ведомые и предлагающие узлы были ограничены алгоритмом от изменений значений которые были приняты большинством. Заметим что "значение никогда не должно быть изменено" относится к значению времени одного исполнения(или запуска / экземпляра / решения) протокола. Типичные алгоритмы репликации запускаются несколько экземпляров алгоритма, но большинство обсуждений алгоритмов фокусируются на одном экземпляре алгоритма для большей простоты понимания. Мы хотим предотвратить историю решений от изменений или удаления.

Для соблюдения этого свойства, предлагающие узлы должны сперва спрашивать ведомые узлы о их (последнем) принятом предложении и значении этого предложения. Если предлагающий узел находит что предложение уже существует, тогда предложение просто отмечается как исполненное вместо того чтобы предлагать его. Лэмпорт говорит об этом так:

> P2b. Если предложение со значением `v` было выбрано, огда каждое предложение с большим номером выданное любым предлагающим узлом должно содержать значение `v`.

Более подробно:

> P2c. Для любого `v` и `n`, если предложение со значением `v` и номером `n` было предложено [лидером], тогда существует множество `S` содержащее большинство принимающих [ведомых] таким образом что либо (a) нет принимающих узлов в `S` которые приняли любое предложение с номером меньше `n` либо (b) `v` это значение последнего по номеру предложения среди всех предложений с номерами меньше чем `n` принятых ведомыми узлами из `S`.

This is the core of the Paxos algorithm, as well as algorithms derived from it. The value to be proposed is not chosen until the second phase of the protocol. Proposers must sometimes simply retransmit a previously made decision to ensure safety (e.g. clause b in P2c) until they reach a point where they know that they are free to impose their own proposal value (e.g. clause a).

If multiple previous proposals exist, then the highest-numbered proposal value is proposed. Proposers may only attempt to impose their own value if there are no competing proposals at all.

To ensure that no competing proposals emerge between the time the proposer asks each acceptor about its most recent value, the proposer asks the followers not to accept proposals with lower proposal numbers than the current one.

Putting the pieces together, reaching a decision using Paxos requires two rounds of communication:

    [ Proposer ] -> Prepare(n)                                [ Followers ]
                 <- Promise(n; previous proposal number
                    and previous value if accepted a
                    proposal in the past)

    [ Proposer ] -> AcceptRequest(n, own value or the value   [ Followers ]
                    associated with the highest proposal number
                    reported by the followers)
                    <- Accepted(n, value)

The prepare stage allows the proposer to learn of any competing or previous proposals. The second phase is where either a new value or a previously accepted value is proposed. In some cases - such as if two proposers are active at the same time (dueling); if messages are lost; or if a majority of the nodes have failed - then no proposal is accepted by a majority. But this is acceptable, since the decision rule for what value to propose converges towards a single value (the one with the highest proposal number in the previous attempt).

Indeed, according to the FLP impossibility result, this is the best we can do: algorithms that solve the consensus problem must either give up safety or liveness when the guarantees regarding bounds on message delivery do not hold. Paxos gives up liveness: it may have to delay decisions indefinitely until a point in time where there are no competing leaders, and a majority of nodes accept a proposal. This is preferable to violating the safety guarantees.

Of course, implementing this algorithm is much harder than it sounds. There are many small concerns which add up to a fairly significant amount of code even in the hands of experts. These are issues such as:

- practical optimizations:
  - avoiding repeated leader election via leadership leases (rather than heartbeats)
  - avoiding repeated propose messages when in a stable state where the leader identity does not change
- ensuring that followers and proposers do not lose items in stable storage and that results stored in stable storage are not subtly corrupted (e.g. disk corruption)
- enabling cluster membership to change in a safe manner (e.g. base Paxos depends on the fact that majorities always intersect in one node, which does not hold if the membership can change arbitrarily)
- procedures for bringing a new replica up to date in a safe and efficient manner after a crash, disk loss or when a new node is provisioned
- procedures for snapshotting and garbage collecting the data required to guarantee safety after some reasonable period (e.g. balancing storage requirements and fault tolerance requirements)

Google's [Paxos Made Live](http://labs.google.com/papers/paxos_made_live.html) paper details some of these challenges.

## Partition-tolerant consensus algorithms: Paxos, Raft, ZAB

Hopefully, this has given you a sense of how a partition-tolerant consensus algorithm works. I encourage you to read one of the papers in the further reading section to get a grasp of the specifics of the different algorithms.

*Paxos*. Paxos is one of the most important algorithms when writing strongly consistent partition tolerant replicated systems. It is used in many of Google's systems, including the [Chubby lock manager](http://research.google.com/archive/chubby.html) used by [BigTable](http://research.google.com/archive/bigtable.html)/[Megastore](http://research.google.com/pubs/pub36971.html), the Google File System as well as [Spanner](http://research.google.com/archive/spanner.html).

Paxos is named after the Greek island of Paxos, and was originally presented by Leslie Lamport in a paper called "The Part-Time Parliament" in 1998. It is often considered to be difficult to implement, and there have been a series of papers from companies with considerable distributed systems expertise explaining further practical details (see the further reading). You might want to read Lamport's commentary on this issue [here](http://research.microsoft.com/en-us/um/people/lamport/pubs/pubs.html#lamport-paxos) and [here](http://research.microsoft.com/en-us/um/people/lamport/pubs/pubs.html#paxos-simple).

The issues mostly relate to the fact that Paxos is described in terms of a single round of consensus decision making, but an actual working implementation usually wants to run multiple rounds of consensus efficiently. This has led to the development of many [extensions on the core protocol](http://en.wikipedia.org/wiki/Paxos_algorithm) that anyone interested in building a Paxos-based system still needs to digest. Furthermore, there are additional practical challenges such as how to facilitate cluster membership change.

*ZAB*. ZAB - the Zookeeper Atomic Broadcast protocol is used in Apache Zookeeper. Zookeeper is a system which provides coordination primitives for distributed systems, and is used by many Hadoop-centric distributed systems for coordination (e.g. [HBase](http://hbase.apache.org/), [Storm](http://storm-project.net/), [Kafka](http://kafka.apache.org/)). Zookeeper is basically the open source community's version of Chubby. Technically speaking atomic broadcast is a problem different from pure consensus, but it still falls under the category of partition tolerant algorithms that ensure strong consistency.

*Raft*. Raft is a recent (2013) addition to this family of algorithms. It is designed to be easier to teach than Paxos, while providing the same guarantees. In particular, the different parts of the algorithm are more clearly separated and the paper also describes a mechanism for cluster membership change. It has recently seen adoption in [etcd](https://github.com/coreos/etcd) inspired by ZooKeeper.

## Replication methods with strong consistency

In this chapter, we took a look at replication methods that enforce strong consistency. Starting with a contrast between synchronous work and asynchronous work, we worked our way up to algorithms that are tolerant of increasingly complex failures. Here are some of the key characteristics of each of the algorithms:

#### Primary/Backup

- Single, static master
- Replicated log, slaves are not involved in executing operations
- No bounds on replication delay
- Not partition tolerant
- Manual/ad-hoc failover, not fault tolerant, "hot backup"

#### 2PC

- Unanimous vote: commit or abort
- Static master
- 2PC cannot survive simultaneous failure of the coordinator and a node during a commit
- Not partition tolerant, tail latency sensitive

#### Paxos

- Majority vote
- Dynamic master
- Robust to n/2-1 simultaneous failures as part of protocol
- Less sensitive to tail latency

---

## Further reading

#### Primary-backup and 2PC

- [Replication techniques for availability](http://scholar.google.com/scholar?q=Replication+techniques+for+availability) - Robbert van Renesse & Rachid Guerraoui, 2010
- [Concurrency Control and Recovery in Database Systems](http://research.microsoft.com/en-us/people/philbe/ccontrol.aspx)

#### Paxos

- [The Part-Time Parliament](http://research.microsoft.com/users/lamport/pubs/lamport-paxos.pdf) - Leslie Lamport
- [Paxos Made Simple](http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf) - Leslie Lamport, 2001
- [Paxos Made Live - An Engineering Perspective](http://research.google.com/archive/paxos_made_live.html) - Chandra et al
- [Paxos Made Practical](http://scholar.google.com/scholar?q=Paxos+Made+Practical) - Mazieres, 2007
- [Revisiting the Paxos Algorithm](http://groups.csail.mit.edu/tds/paxos.html) - Lynch et al
- [How to build a highly available system with consensus](http://research.microsoft.com/lampson/58-Consensus/Acrobat.pdf) - Butler Lampson
- [Reconfiguring a State Machine](http://research.microsoft.com/en-us/um/people/lamport/pubs/reconfiguration-tutorial.pdf) - Lamport et al - changing cluster membership
- [Implementing Fault-Tolerant Services Using the State Machine Approach: a Tutorial](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.4762) - Fred Schneider

#### Raft and ZAB

- [In Search of an Understandable Consensus Algorithm](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf), Diego Ongaro, John Ousterhout, 2013
- [Raft Lecture - User Study](http://www.youtube.com/watch?v=YbZ3zDzDnrw)
- [A simple totally ordered broadcast protocol](http://research.yahoo.com/pub/3274) - Junqueira, Reed
- [ZooKeeper Atomic Broadcast](http://research.yahoo.com/pub/3514)
