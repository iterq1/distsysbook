# %chapter_number%. Репликация: протоколы обеспечивающие слабую согласованность

Сейчас, после того как мы расмотрели протоколы которые обеспечивают последовательную согласованность с учетом возрастающего количества обрабатываемых типов отказов, давайте вернемся к пространству возможных опций, которое открывается если мы откажемся от требования последовательной согласованности(без расхождений).

В общем и целом, трудно придумать одно измерение которое будет определять или характиризовать протоколы позволяющие репликам расходится. Большинство таких протоколов обеспечивают высокую доступность и ключевой проблемой является смогут ли конечные пользователи найти гарантии, абстракции, API полезные для их нужд, несмотря на то что реплики могут расходится, когда отказывают узлы или рвется сеть.

Почему слабо согласованные системы менее популярны?

Как я говорил в введении, я думаю что многое в распределенном программировании следует из двух последствий распределенности:

- информация путешествует со скоростью света
- независимые вещи отказывают независимо

Следствием того что скорость распространения информации ограничена, является то что каждый узел воспринимает окружающий мир по-своему. Вычисления на одному узле просты, так как все случается в определенном глобальном и абсолютном порядке. Вычисления на распределенной системе сложны, так как глобального  и абсолютного порядка нет.

Долгое время (десятилетия исследований), мы решали эту проблему введение глобального порядка. Мы обсудили много методов достигающий последовательной согласованности путем создания порядка(с учетом устойчивости к отказам) когда естественного порядка не было.

Конечно, проблема в том что создание порядка крайне затратно. Это зачастую просто невозможно в больших системах работающих в интернете, когда система должна оставатся доступна. Система соблюдающая строгую согласованность ведет себя не как распределенная: она ведет себя как единая система, что плохо для доступности во время разделений.

Кроме того, для каждой операции зачастую большинству узлов необходимо связатся друг с другом - и зачастую не один раз, а дважды(вспомним обсуждение 2PC). Это обычно крайне болезнено для систем которые нуждаются в географической распределенности для обеспечения адекватной производительности для пользователей в разных частях мира.

Так что поведение системы по умолчанию как единого целого возможно не желательно.

Возможно то что мы хотим, это система для которой мы можем писать код без больших затрат на координаци но при это продолжать получать пригодные для наших целей результаты. В замен единственно-верной версии данных, мы принимаем разные реплики с расхождениями между друг другом - это позволит сохранить эффективность и сохранить устойчивость к разделению - и затем мы попробуем найти способ справится с расхождениями каким либо образом.

Согласованность в конечном итоге выражается в следующей идее: узлы которые могут иногда расходится в конечном итоге прийдут к согласию насчет единого значения.

Во всем множестве систем предоставляющем согласованность в конечном итоге, можно выделить два типа архитектур:

*Согласованность в конечном итоге с вероятностными гарантиями*. Этот тип систем может определять конфликты на каком то этапе после их появления, но не дает гарантий что результаты будут эквивалентны результатам корректного порядка исполнения операций. Другими словами, конфликтующие обновления иногда будут перезаписывать новые значения старыми и некотрые аномалии могут проявлятся во время нормального проведения операций(или во время разделения).

В недавние годы,наиболее известная система жертвующая согласованностью на уровне одной копии это Amazon Dynamo, которую я буду обсуждать в качестве системы которая предалагает согласованность в конечном итоге с вероятностными гарантиями.

*Согласованность в конечном итоге со строгими гарантиями*. Этот тип систем гарантирует что результат будет сходится к одному значению эквивалентному полученному при корректной последовательности операций. Другими словами, такие системы не приводят к аномальным результатам; без какой либо координации вы можете создавать реплики сервисов, которые будут коммуницировать любым способом и получать обновления в любом порядке и в конечном итоге они достигнут согласия насчет конечного результата на все время пока они будут видеть одну и туже информацию.

CRDT (сходяющиеся рпелицирующиеся типы данных) это типы данных гарантирующие сходимость к одному и тому же значению несмотря на разделы и задержки в сети и изменение порядка сообщений. Они доказанно сходимы, но ограничены типами данных которые могут быть реализованы как CRDT.

CALM (согласованность как логическая монотонность) гипотеза это альтернативное выражение тех же самых принципов: это уравнивание логической монотонности и сходимости. Если мы можем сделать вывод что чтолибо логически монотонно, тогда мы также можем безопастно запускать это без какой либо координации. Анализ слияний - в частности, применительно к языку программирования Bloom - может быть применен для принятия решений в программировании о том когда и где  использовать координационные техники из строго согласованной системы и когда можно безопастно выполнять операции не пребегая к вычислительно "дорогой" координации.

## Согласование разного порядка операций

Что делает систему не поддерживающей согласованность единной копии? Давайте попробуем сделать более конкретные выводы из нескольких примеров.

Конечно наиболее очевидной характеристикой систем которые не обспечивают согласованности одной копии является, то что они позволяют репликам расходится относительно друг друга. Это означает что нет строгой коммуникации: реплики могут быть отделены друг от друга и даже продолжать быть доступны и записывать данные.

Давайте представим систему из трех реплики, каждая из которых отделена от других. Для примера реплика может быть в другом датацентре или отделена по другим причинам. Каждая реплика остается доступной во время разделения для записи и чтения для некотрого набора клиентов:

    [Клиенты]   - > [A]

    --- Раздел ---

    [Клиенты]   - > [B]

    --- Раздел ---

    [Клиенты]   - > [C]

После некотрого времени, разделение исчезает и реплики начинают обменниваться информацией. Они получают  различные обновления от разных клиентов что приводит к расхождениям - следовательно необходим некотрый способ согласования. Нам бы хотелось бы чтобы все реплики после этого сошлись к одному результату.

    [A] \
        --> [мерж]
    [B] /     |
              |
    [C] ----[мерж]---> результат


Другой путь размышлять о системах с гарантиями слабой согласованности это представить множество клиентов отсылающих сообщения на узла в некотром порядке. Так как у нас нет координационного протокола чтобы обеспечить глобальный единый порядок, сообщения могут быть доставлены в разном порядке на разные реплики:

    [Клиенты]  --> [A]  1, 2, 3
    [Клиенты]  --> [B]  2, 3, 1

Это в сущности причина по которой мы нуждаемся в протоколах координации. Для примера, предположим что мы пытаемся склеить строку за 3 операции:

    1: { операция: concat('Hello ') }
    2: { операция: concat('World') }
    3: { операция: concat('!') }

Тогда, без координации A получит "Hello World!", а B "World!Hello ".

    A: concat(concat(concat('', 'Hello '), 'World'), '!') = 'Hello World!'
    B: concat(concat(concat('', 'World'), '!'), 'Hello ') = 'World!Hello '


Это конечно же некорректно. Опять же, нам бы хотелось чтобы реплики сходились к одному результату.

Держа в уме оба этих примера, давайте взглянем на Amazon's Dynamo в первую очередь чтобы определить базовый уровень и затем обсудим ряд концепций для построения систем со слабой консистентностью, таких как CRDT the CALM теорема.


## Amazon's Dynamo

Архитектура Amazon's Dynamo (2007) это возможно наиболее известный пример системы представляющей слабые гарантии согласованности и являющейся высоко-доступной системой. Это основа для многих промышленных систем таких как LinkedIn's Voldemort, Facebook's Cassandra и Basho's Riak.

Dynamo это ключ-значение хранилище обеспечивающее согласованность в конечном итоге и высокую доступность. Ключ-значение хранилище напоминает огромную хеш-таблицу: клиент может установить некоторое значение по ключу используя `set(key, value)` и получить некоторое значение по ключу используя `get(key)`. Dynamo кластер содержит N частей узлов; каждый узел отвечает за определенный набор ключей.

Dynamo разработана с приоритетом доступности над согласованностью; согласованность на уровне одной активной копии не гарантируется. Реплики могут расходится относительно друг друга когда значения записываются; во время чтения по ключу, происходит фаза согласования во время которой различия разных реплик обьединяются перед тем как возвратить результат клиенту.

Для многих отраслей бизнесса Amazon, более важно избегать простоев нежели держать данные в полной консистентности, так как отключение может привести к бизнесс-потерям и утрате доверия клиентов. Более того, если данные не особо важные, тогда системы с слабой согласованностью могут предоставлять лучшую производительность и более высокую доступность с более низкими затратами нежели традиционные RDBMS.

Dynamo это полная архитектура системы, в которой необходимо расмотреть много различных частей некоторые из которых выходят за рамки задачи репликации; особенно, как запись диспатчеризируется между узлами и как происходит запись на несколько узлов.

    [ Клиент ]
        |
    ( Отображение ключей в узлы )
        |
        V
    [ Узел A ]
        |     \
    ( Синхронная часть репликации: минимум надежности )
        |        \
    [ Узел B]  [ Узел C ]
        A
        |
    ( Определение конфликта; асинхронная часть репликации:
      обеспечивает востановление разделенных / упавших узлов )
        |
        V
    [ Узел D]

После того как мы взглянем как запись принимается после иницирования клиентов, мы посмотрим как обнаруживаются конфликты и на асинхронную часть репликации. Это часть необходима, из-за дизайна высоко-доступных решений, в которых узлы могут быть временно недоступны(изза отказа или разделения). Синхронизация реплик обеспечивает довольно быстрое приведение реплики к актуальному состоянию даже после отказа.

### Согласованное хэширование(Consistent hashing)

Записываем мы или читаем, первое что должно произойти мы должны определить где данные должны находится в системе. Это требует некотрого отображение ключей в узлы на которых они хранятся.

В Dynamo, ключи отображаются в узлы используя технику хеширования известную как [согласованное хеширование](https://github.com/mixu/vnodehash) (которое я не буду обсуждать детально). Главная идея это что ключи могут быть отображены в набор узлов при помощи простых вычислений на клиенте. Это значит что клиент может обнаружить ключи без запроса к системе для определения расположения ключа; это экономит системные ресурсы так как хеширование во много раз быстрее чем вызов удаленной процедуры.

### Частичный кворум

После того как мы разобрались как ключ должен хранится, мы должны понять как хранится значение. Это синхронная задача; причина по которой нам надо записывать немедленно значение на несколько узлов это предоставление высокого уровня надежности (например для защиты от немедленного отказа узла).

Так же как и Paxos или Raft, Dynamo использует кворумы для репликации. Однако Dynamo кворумы нестрогие(основанные только на часте узлов) в отличии от строгих(основанных на большинстве) кворумов.

Неформально, строгие системы кворумов это системы кворумов с таким свойством что любые два кворума в системе пересекаются. Требование большинства голосов для обновления перед его принятием гарантирует что только одна версия истории изменений будет признаной для каждого мажоритарного кворума так как каждый такой кворум будет пересекатся с другим хотя бы в одном узле. На это свойство опирается к примеру Paxos.

Частичный кворум не удовлетворяет этому свойству; это означает что большинство не требуется и различные подмножества кворума могут содержать различные версии одних и тех же данных. Юзер может выбирать число узлов для записи и чтения:

- пользователь может выбрать некотрое число W-из-N узлов требуемое для того чтобы запись была успешна; и
- пользователь может определить число узлов (R-из-N) которым необходимо контактировать при чтении.

`W` и `R` определяет число узлов которые должны быть вовлечены в процесс записи и чтения. Запись с использованием большего числа узлов будет более медленной но повысит вероятность того что значение не будет потеряно; чтение с большего числа узлов повышает вероятность того что прочитанное значение будет актуально.

Типичная рекомендация это `R + W > N`, потому что это означает что кворумы для чтения и записи пересекаются хотя бы в одном узле - что делает менее вероятным что устаревшее значение будет прочитано. Обычная конфигурация это `N = 3` (то есть всего 3 рпелики для каждого значения); это означает что юзер может выбирать между:

     R = 1, W = 3;
     R = 2, W = 2 или
     R = 3, W = 1

В более общем плане `R + W > N`:

- `R = 1`, `W = N`: быстрое чтение, медленная запись
- `R = N`, `W = 1`: быстрая запись, медленное чтение
- `R = N/2` and `W = N/2 + 1`: хорошо и для того и для того

N редко больше 3, так как хранение большого числа копий может быть дорогостояще для большого количества данных!

Как я упомянал ранее, публикация Dynamo  вдохновила многие подобные системы. Они все используют репликацию на основе частичных кворумов, но с другими N, W и R по умолчанию:

- Basho's Riak (N = 3, R = 2, W = 2 по умолчанию)
- Linkedin's Voldemort (N = 2 or 3, R = 1, W = 1)
- Apache's Cassandra (N = 3, R = 1, W = 1)

Так же есть другой ньюанс: когда отправляется запрос на запись или чтение, все N узлов опрашиваются (Riak), или только некоторое число узлов - минимальный кворум (то есть R или W; Voldemort). Отправка всем более быстра и менее чувствительна к задержкам(так как можно ждать ответ только R или W узлов из N) но менее эффективен, Отправка запроса только минимуму узлов более чувствительна к задержкам(так как задержка в общении с одним узлом приведет к задержке всей операции) но более эффективно (меньше сообщений / соединений в целом)

Что случится когда кворумы записи и чтения перекрываются то есть (`R + W > N`)? В частности, зачастую говорят что в  результате мы получим "строгую согласованность".

### R + W > N это тоже самое что и "строгая согласованность"?

Нет.

Для этого нет оснований: система где `R + W > N` может определять конфликты записи и чтения, так как кворумы для записи и чтения пересекаются. Например хотя бы один узел будет обоих кворумах:

       1     2   N/2+1     N/2+2    N
      [...] [R]  [R + W]   [W]    [...]

Это гарантирует что предыдущая запись будет видна для последующих чтений. Однако, это так только если число узлов N никогда не будет менятся. Следовательно, Dynamo не сдерживает этих гарантий, потому что в Dynamo кластер может быть изменен если узлы откажут.

Dynamo разработана чтобы быть всегда доступной для записи. Она содержит который обрабатывает отказ узлов путем добавления другого не связанного сервера в набор узлов отвественных за хранение определенных ключей пока другой узел не работает. Это означает что кворум не гарантирует пересечений всегда. Даже `R = W = N` не будет этого гарантировать, так как пока размер кворума N узлы в кворуме могут менятся изза отказов. В частности, во время раздела, если достаточное число узлов не может быть достигнуто, Dynamo будет добавлять новые узлы из несвязанных с исходными но доступных узлов.

Кроме того, Dynamo не обрабатывает разделы так же как система с строгой согласованностью, а именно: она позволяет записывать данные по обе стороны раздела сети, это означает что система не действует так как если бы она не была распределенной. Поэтому называть `R + W > N` "строго согласованным" ошибочно; гарантии только лишь вероятностные - что не подходит для строго согласованной системы.

### Определение конфликтов и чтение исправленых записей

Системы которые которые позволяют репликам расходится должны иметь способ в конечном итоге согласовать два различных значения. Как кратко упоминалось в ходе обсуждения подходов основанных на частичном кворуме, один из способов это использовать определение конфликтов во время чтения а затем применить какой-либо алгоритм разрешения конфликтов. Но как это сделать?

В общем случае, Iэто можно сделать путем отслеживание причинноследственных связей между кусочками данных через сохранненые в них метаданные. Клиенты должны получить метаданные когда они читают данные из системы и они должны вернуть назад значение метаданных когда они записывают данные в базу данных.

Мы уже встречались с методом который делает это: векторные часы могут быть использованы для представления истории некотрого значения. В самом деле, именно их использует оригинальная архитектура Dynamo для определения конфликтов.

Однако, использование векторные часы не единственная альтернатива. Если взглянуть на архитектуру многих промышленных систем, можно понять немного о том как они работают глядя на метаданные которые они отслеживают.

*Без метаданных*. Когда система не отслеживает метаданные, и всегда возвращает только значение(с помощью клиентского API), у нее нет возможности как либо специально обрабатывать конкурентные записи. Общее правило в таких системах "last writer wins": другими словами, если два записывающих клиента пишут в одно и тоже время, только значение от более медленного клиента будут сохранятся.

*Временные метки*.  Формально, значение с более поздней временной меткой "выигрывает". Однако, если время не синхронизированно точно могут происходить многие странные случаи когда новое значение(из части системы с отстающим временем) будет затерто более старым. Facebook Cassandra это реализация архитектуры Dynamo которая использует временные метки вместо векторных часов.

*Номера версий*. Номера версий могут помочь избежать могих проблем использования временных меток. Однако для отслеживания нескольких причинно-следственных связей недостаточно номеров версий и необходимы векторные часы.

*Векторные часы*. Используя векторные часы,  конкурентные и устаревшие обновления могут быть обнаружены. Выполнение исправления при чтении также становится возможным, хотя в некотрых случаях(конкурентные изменения) необходимо спрашивать у клиента значение. Это так потому что если изменения паралельные и мы не знаем ничего больше о данных(как в нашем случае когда мы работаем с хранилищем ключ-значение), тогда лучшей политикой будет спросить нежели отбросить данные произвольно.

Когда происходит чтение значения, клиент контактирует с `R` из `N` узлов и опрашивает их о последнем значении для ключа. Далее берет все их ответы и отбрасывает значения которые строго более старые(для этого используются векторные часы). Если остается только одна уникальная пара векторные часы + значение, тогда возвращается она. Если остается несколько таких пар(которые редактировались конкурентно), тогда возвращаются все они.

Из этого очевидно что чтение исправленных записей может возврашать множество значений. Это означает что клиент / приложение должно уметь время от времени обрабатывать случаи выбирая значение на основе конкретного критерия в каждом отдельном взятом случае.

В дополнение, ключевой компонент промышленных систем с векторными часами это то что часы не могут расти вечно - так что необходимо иногда собирать мусор безопастным способом чтобы не нарушить требования отказоустойчивости хранилища.

### Синхронизация реплик: gossip и деревья Меркла

При условии что Dynamo-архитектура устойчива к падениям узлов и разделениям сети, она должна уметь пересоединять кластер после разделения или заменять упавший узел или присоединять востановившийся.

Синхронизация реплик используется для обновления реплик до актуального состояния после отказа и для периодической синхронизации реплик между друг другом.

Gossip это вероятностный способ для синхронизации реплик. Это паттерн коммуникации (то есть способ которым узел общается с узлом) не детерминирован заранее. Вместо этого, узлы имеют некотрую вероятность `p` того что узел попытается синхронизироватся с другими. Каждые `t` секунд, каждый узел выбирает узел с которым будет коммуницировать. Это обепечивает дополнительный механизм за пределами синхронной части репликации (такой как частичный кворум записи) который приводит копии в актуальное состояние.

Gossip это масштабируемое и без единой точки отказа, но предоставляющее только вероятностные гарантии.

Для того чтобы сделать обмен информацией во время синхронизации реплик эффективных, Dynamo использует технику под названием деревья Меркла, которые я не буду описывать в деталях. Ключевой идея это то что данные могут быть захешированы на нескольких уровнях детализации: хеш всего контента, хеш половины ключей, четверти и так далее.

Поддерживая этот довольно детализированный хеш, узлы могут сравнивать данные которые хранят более эффективно чем сравнение в лоб. После того как узлы определили какие узлы содержат различные значения они могут обменится необходимой информацией чтобы привести реплики в актуальному состоянию.

### Dynamo на практике: вероятностное ограничение устаревания (PBS)

Это в значительной степени охватывает архитектуру Dynamo:

- согласованное хеширование для определения расположения ключа
- частичный кворум для записи и чтения
- определение конфликтов и чтение исправлений используя векторные часы
- gossip для синхронизации реплики

Как можно было бы охарактеризовать поведение такой системы? Довольно недавняя публикация Bailis (2012) описывает подход названный  [PBS](http://pbs.cs.berkeley.edu/) (вероятностное ограничение устаревания) использует симуляцию и сбор данных о промышленных системах чтобы охарактеризовать ожидаемое поведение подобной системы.

PBS оценивает степень несогласованности используя информацию о уровне анти-энтропии (gossip), сетевых задержек и задержек локальной обработки чтобы определить ожилаемый уровень согласоваанности чтения. Этот прием реализован в Cassandra, где временная информация скомбинирована на разных сообщениях и оценка расчивается на основе этой информации сэмулированной методом Монте-Карло.

Основываясь на публикации, во время нормальных операций(без каких либо сетевых и прочих проблем) время согласования данных зачастую намного меньше и можно читать согласованные данные за десятки-сотни миллисекунд. Таблица ниже показывает количество времени требуемое для 99.9% вероятности прочтения согласованных данных при различных настройках `R` и `W`(получена в результате анализа оптыных данных времени синхронизации из LinkedIn(SSD и 15k RPM disks) и Yammer) :

![из публикации о PBS](./images/pbs.png)

Для примера, при переходе от `R=1`, `W=1` к `R=2`, `W=1` в Yammer продолжительность случаев несогласованности сокращается от 1352 мс до 202 мс - при удержани времени задержки при чтении на низком уровне (32.6 ms) что быстрее чем в режиме строгого кворума (`R=3`, `W=1`; 219.27 ms).

Для большего погружения, смотрите [PBS сайт](http://pbs.cs.berkeley.edu/) и саму публикацию.

## Программирование в неупорядоченной манере

Давайте вернемся назад к примерам типов проблем которые нам бы хотелось решить. Первый сценарий содержит 3 различных сервера с разделением; когда разделение устранено, мы хотим чтобы сервера сошлись к одному и тому же значению. Amazon's Dynamo делает это возможным путем чтения значений с `R` из `N` узлов и после выполняя согласование значения.

Во втором примере, у нас содержится более специфичная операция - соединение строк. Оказывается что мы не знаем технику сделать обьединение строк без учета порядка операций (то есть без дорогой координации). Однако, иммеются операции которые могут быть применены безопастно в любом порядке, там где простая запись не может гарантировать корректность. Как пишет Pat Helland:

> ... Работа основанная на операциях может быть коммутативной (с правильными операциями и правильной семантикой) в то время как простая семантика ЗАПИСЬ/ЧТЕНИЕ не поддается обеспечению коммутативности.

Для примера, возьмем систему которая реализует простой механизм оплаты с операциями `дебит` и `кредит` двумя способами:

- используя ячейку данных с операциями `запись` и `чтения`
- используя целочисленный тип с встроенными операциями `дебит` и `кредит`

Последняя реализация знает больше о внутреннем устройстве типа данных и может сохранять итог  операций несмотря на то что порядок операций может быть изменен. Дебит или кредит могут быть применены в любом порядке и получится один и тот же результат:

    100 + кредит(10) + кредит(20) = 130 and
    100 + кредит(20) + кредит(10) = 130

 Однако, запись фиксированных значений не может быть переупорядочена: если запись будет переупорядочена то тогда она перепишет другую:

    100 + запись(110) + запись(130) = 130 but
    100 + запись(130) + запись(110) = 110

Давайте возьмем пример из начала этой главы но используем другие операции. В этом сценарии, клиенты шлют сообщения двум узлам, которые видят операции в разном порядке:

    [Клиенты]  --> [A]  1, 2, 3
    [Клиенты]  --> [B]  2, 3, 1

Вместо обьеднения строк, Instead of string concatenation, преположим что мы ищем наибольшее значение (то есть max()) для множества целых чисел. Сообщения 1, 2 и 3 таковы:

    1: { операция: max(предыдущий, 3) }
    2: { операция: max(предыдущий, 5) }
    3: { операция: max(предыдущий, 7) }

То есть, без координации мы придем к одному и тому же значению - 7:

    A: max(max(max(0, 3), 5), 7) = 7
    B: max(max(max(0, 5), 7), 3) = 7

В обоих случаях, обе реплики видели обновления в разном порядке, но объединение результатов привело к получению одного и того же значения независимо от порядка. Результат сошелся в обоих случаях потому что была использована процедура обьединения (`max`).

Вполне веротяно что мы не можем написать процедуру обьединения для всех типов данных. В Dynamo, значение это бинарный файл, так что лучшее что можно сделать это просить приложение разрешить конфликты после каждого такого случая.

Однако, если мы знаем что данные более специфичного вида, мы можем обрабатывать возможные типы конфликтов. CRDT это структуры данных разработанные для предоставления типов данных которые всегда сходятся к одному значению если они получают одинковый набор изменений (без учета порядка).

## CRDT: Сходящиеся реплицируемые типы данных

CRDTs основывается на знаениях о свойствах коммутативности и ассоциативности специфических операций над специфицическими типами данных.

Для того чтобы набор операций сходился к определенному значению в ситуации когда реплики коммуницируют время от времени, операции должны быть порядко-независимыми и не чувствительными к дупликации/переотправке сообщений. Таким образом, операции должны быть:

- Ассоциативными (`a+(b+c)=(a+b)+c`), то есть перегруппировки должны не изменять результата
- Коммутативными (`a+b=b+a`), то есть порядок применения должен быть неважен
- Идемпотентными (`a+a=a`), то есть повторное применение не должно влиять на результат

Это возврашет нас к структурам которые уже известны в математике; они известны как объединяемые или сходящиеся [полурешетки](http://en.wikipedia.org/wiki/Semilattice).

[Полурешетка](http://en.wikipedia.org/wiki/Lattice_%28order%29) это частично упорядоченный набор с единственной верхней границей и единственной нижней границей. Полурешетка напоминает обычную решетку но с единственной верхней и нижней границей. Обьединяемые полурешетки имеют только верхнюю границу, а сходящиеся только нижнюю.

Любой тип данных который может быть выражен как полурешетка может быть реализован как структура данных с гарантиями сходимости. Для примера, подсчет  `max()` набора значений всегда будет возврашать одно и то же значение независимо от порядка получаемых значений, всегда пока значения будут поступать, потому что операция `max()` ассоциативна, коммутативна, и идемпотентна.

Для примера, здесь две полурешетки: первая отображает набор где оператором обьединения служит функция `union(items)`, во второй мы имеем строго возрастающий счетчик с оперетором объединения `max(values)`:

       { a, b, c }              7
      /      |    \            /  \
    {a, b} {b,c} {a,c}        5    7
      |  \  /  | /           /   |  \
      {a} {b} {c}            3   5   7

С типами данных которые могут быть выражены полурешетками, мы можем иметь реплики которые коммуницирует любым способом и получают обновления в любом порядке, и они будут в конечном счете сходится к конечному результату, до тех пор пока они получают одну и ту же информацию. Это наиболее сильное свойство которое мы можем гарантировать, до тех пока мы выполняем предпосылки.

Однако, выражение типов данных в виде полурешеток зачастую требует некотрого уровня интерпретации. Многие типы данных имеют операции которые не подходят для того чтобы быть выражеными порядко-независимыми. Для примера, добавление элемента в множество ассоциативно, коммутативно и идемпотентно. Однако, если мы также позволяем удалять элементы тогда необходим способ разрешать конфликтуюшие операции вроде `добавить(A)` и `удалить(A)`. Что означает удалить элемент если этот элемент никогда не был добавлен в локальную реплику?  Решение этого вопроса должно быть определено в порядко-независимой манере, и есть несколько различных вариантов с разными компромисами.

Это означает что несколько похожих типов данных имеют более узкоспециализированную реализацию как CRDT которая идет на различные компромиссы с упорядоченностью чтобы разрешать конфликты в порядко-независимым способом. В противоположность ключ-значение хранилищу которая оперирует простыми ячейками (то есть значениями служат файлы непрозрачной структуры с точки зрения системы), при использовании CRDT необходимо использовать правильный тип данных чтобы избежать аномалий.

Несколько примеров различных типов данных определенных как CRDT:

- Счетчики
  - Постоянно возрастающий счетчик (функция объединения = max(values); содержимое = single integer)
  - Положительно-отрицательный счетчик (содержит два возрастающих счетчика, один для прибавлений, другой для вычитаний)
- Ячейки
  - "Last Write Wins" - ячейки (временные метки или номера версий;функция объединения = max(ts); содержимое = blob)
  - Ячейка с множественным значением (векторные часы; функция объединения = take both)
- Множества
  - Только увеличивающиеся множество (функция объединения = union(items); сожержимое = set; элементы не удаляемы)
  - Двух-фазное множество (содержит два множества, одно для добавленных элементов, и другое для удаленных; элементы можно удалить и добавить один раз)
  - Уникальное множество (оптимизированная версия двух-фазного)
  - "Last write wins" множество (функция объединения = max(ts); сожержимое = set)
  - Положительно-негативное множество (содержит PN-счетчик для каждого элемента)
  - Observed-remove множество
- Графы и техтвые последовательности(см. публикацию)

Для обеспечения операций без аномалий, ты должен найти правильный тип данных для своего приложения - для примера, если ты значешь что ты будешь удалять один элемент только один раз - двух-фазное множество будет отлично работать; если ты будешь только добавлять элементы тогда сгодится и только возрастающее множество.

Не все типы данных имеют известные реализации CRDT, но созданы CRDT имплементации для булевых констант, счетчиков, множеств, регистров, графов (2011) [ислледовательская публикация от Шапиро и других](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf).

Интересно, что реализация ячейки напрямую соотвествует реализациям хранилищ ключ значение: last-write-wins ячейка использует временные метки и просто сходится к значению с наибольшей меткой времени; ячейка с множественным значением соотвествует стратегии сохранения и разрешения конфликтующих записей Dynamo. Для более глубокого погружения я рекомендую взглянуть на публикацию в секции "для дальнейшего чтения" этой главы.

## CALM теорема

CRDT основаны на осознание того факта что структуры данных выражженные как полурешетки сходятся. Но программирование это не только изменение состояния, если только вы не разрабатываете хранилище данных.

Несомненно, порядко-независимость это важное качество для сходимости любых вычислений: если порядок в котором получаются данные влияет на результат вычислений, нет способа выполнять вычисления без гарантии определенного порядка.

Однако, существуют многие модели программирования в которых порядок операторов не играет важной роли. Для примера, в [MapReduce model](http://en.wikipedia.org/wiki/MapReduce), и Map и Reduce задачи определяют как задачи обработки кортежей без внутреннего состояния которые необходимо запустить на наборе данных. Конкретные решения о том как и в каком порядке данные должны поступать в задачи не определяются явным образом, вместо этого планировшик сам отвечает за распределение задач между узлами в кластерах и порядком их запуска.

Похожим образом, в SQL мы только записываем запрос но не определяем как его выполнять. Запрос это простая декларативная запись задачи и работой оптимизатора запросов является выяснить эффективный способ выполнения запроса (распределив выполнение между машинами, базами и таблицами).

Конечно, эти модели программирования не такие универсальные как ящыки общего назначения. MapReduce задачи должны быть выражены как чистые функции в ациклическом пути исполнения программы; SQL команды могут выполнять довольно сложные вычисления но многие вещи довольно трудно представимы в них.

Однако, это два простых примера которые показывают что есть много задач обработки информации которые поддаются выражению в декларативном языке в котором явно не указывается порядок. Модель программирования которая выражает желаемый результат без явного указания порядка вычислений(оставляя его оптимизатору) имеют порядко-независимую семантику. Это означает что программы могут быть выполнены без координации, поскольку они зависят от входных данных но не зависят от порядка получаемых данных.

Ключевая идея что такие программы *могут быть* безопастными при выполнении без координации. Без явного правила которое характеризует то что является безопастным для выполнения без координации, а что нет, мы не можем реализовать программу оставаясь уверенным, что результат работы программы корректен.

Именно об этом говорит CALM теорема. CALM теорема  основана на осознании связи между логической монотонностью и полезной для использования формой согласованности в конечном итоге (то есть слияния/сходимости). Она утверждает что логически монотонная программа будет согласованной в конечном итоге.

Следовательно, если мы знаем что некотрые вычисления логически монотонны, значит мы знаем что данные вычисления безопастно запускать без координации.

Для лучшего понимания этого, мы должны увидеть разнницу между логически монотонными вычислениями и [не логически монотонными](http://plato.stanford.edu/entries/logic-nonmonotonic/).

<dl>
  <dt>Монотонность</dt>
  <dd>Если утверждение `φ` является следствием из множества предпосылок `Γ`, тогда оно может быть выведено из любого множества предпосылок `Δ` расширяющего `Γ`</dd>
</dl>

Большинство стандартных логических структур монотонны: любые выводы сделанные в рамках логики первого порядка, при дедуктивном выводе, не могут быть опровергнуты новой информацией. Не монотонная логика это система в которой данное свойство не сдерживается - другими словами, некотрые выводы в такой системе могут быть опровергнуты новыми данными.

В сообществе разработчиков исскуственного интеллекта, не монотонная логика ассоциируется с [опровергаемыми расуждениями](http://plato.stanford.edu/entries/reasoning-defeasible/) - расуждениями, в которых предположения сделанные на части информации могут быть опровергнуты новой информацией. Для примера, если вы узнаете что Твити это птица, вы предположите что Твити умеет летать; но если вы позже узнаете что Твити это пингвин тогда вам приедется пересмотреть свое предположение.

Монотонность касается отношений между предпосылками (или фактами о окружающей среде) и заключениями (или утверждениями об окружающей среде). В монотонной логике мы знаем что наши результаты не пересматриваемы: [монотонные](http://en.wikipedia.org/wiki/Monotonicity_of_entailment) вычисления не нужнаются в перевычислениях или координации; ответ становится все более точным с течением времени. Однажды узнав что Твити это птица (и что мы рассуждаем с использованием монотонной логики), мы можем безопастно заключить что Твити может летать и что ничего что мы узнаем не заставит нас отказатся от этого заключения.

В то время как любые вычисления что вычисляют человеко-читабельный результат могут быть интерпретированы как утверждения об окружающем мире, определение является ли вычисление в программе исполняемой на фон-Нейманновской машине монотонным трудно, потому что не совсем очевидны отношения между фактами и утверждениями и являются ли эти отношения монотонными.

Однако, существует некотрые модели программирования которые можно определить как монотонные. Например, [реляционная алгебра](http://en.wikipedia.org/wiki/Relational_algebra) (теория лежащая в основе SQL) и [Datalog](http://en.wikipedia.org/wiki/Datalog) предоставляющие высокоуровневые языки которые имеют хорошо понятные интерпретации.

Оба(Datalog и реляционная алгебра - даже с рекурсией), как известно, монотонны. Более конкретно, вычисления выраженные с использованием определенного набора базовых операторов - выборка, проекция, естественное соединение, декартово произведение, объединение и рекурсивный Datalog без отрицаний) - монотонны, и становятся не монотонными при добавлении более продвинутых операторов (отрицание, вычитание, деление, квантор всеобщности, группировка).

Это означает что вычисления выраженные с использованием значительного количества операторов (таких как map, filter, join, union, intersection) в твоей системе логически монотонны; любые вычисления использующие эти вычисления также монотонны и таким образом их можно безопастно запускать без координации. Выражения которые используют отрицания или группировки, напротив делают невозможным запуск таких вычислений без координации.

Это важно для понимания связи между немонотонностью и операциями которые очень ресурсоемки при апуске в распределенной системе. Конкретно, и *распределенная группировка* и *протоколы координации* считаются одной из форм отрицания. Как Joe Hellerstein [писал](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf):

> Для обеспечения достоверности отрицательного предиката в распределенной среде, стратегия вычисления должна начать "подсчет с 0", чтобы определить пустоту, и ждать пока распределенный процесс подсчета определится как завершенный. Группировка это обобщение этой идеи.

и:

> Эта идея может быть расмотрена с другой стороны также хорошо. Протоколы координации это сами аггрегатами, так как они представляют из себя голосования: двух-фазный коммит требует единодушного голосования, Paxos требует большинство голосов, и Византийский протокол требует 2/3 большинства. Ожидание требует подсчета.



Если, мы можем выразить наши вычисления способом в котором возможно проверить монотонность, тогда мы можем выполнить статический анализ всей программы и определить участки программы которые будут согласованны в конечном итоге без координации (монотонные участки) - и которые не соотвествуют этому требованию (не монотонные).

Заметим что это требует других типов языков, поскольку эти выводы сложно сделать для традиционных языков, где последовательности, выборки и итерация встроены в само ядро. Это причина по которой был разработан язык Bloom.


## Для чего может быть полезна не монотонность вычислений?

Разница между монотонность и не монотонностью крайне интересна. Для примера, сложение двух числе монотонно, но подсчет аггрегации двух узлов содержащих числа не монотонно. В чем же разница? Первое это вычисление (сложение двух чисел), а второе это утверждение (расчет аггрегата).

В чем разница между утверждением и вычислением? Давайте расммотрим запрос "Пицца это овощ?". Для ответа, мы должны вникнуть в суть: когда приемлимо сделать вывод что чтолибо верно(или не верно)?

There are several acceptable answers, each corresponding to a different set of assumptions regarding the information that we have and the way we ought to act upon it - and we've come to accept different answers in different contexts.

In everyday reasoning, we make what is known as the [open-world assumption](http://en.wikipedia.org/wiki/Open_world_assumption): we assume that we do not know everything, and hence cannot make conclusions from a lack of knowledge. That is, any sentence may be true, false or unknown.

                                    OWA +             |  OWA +
                                    Monotonic logic   |  Non-monotonic logic
    Can derive P(true)      |   Can assert P(true)    |  Cannot assert P(true)
    Can derive P(false)     |   Can assert P(false)   |  Cannot assert P(true)
    Cannot derive P(true)   |   Unknown               |  Unknown
    or P(false)

When making the open world assumption, we can only safely assert something we can deduce from what is known. Our information about the world is assumed to be incomplete.

Let's first look at the case where we know our reasoning is monotonic. In this case, any (potentially incomplete) knowledge that we have cannot be invalidated by learning new knowledge. So if we can infer that a sentence is true based on some deduction, such as "things that contain two tablespoons of tomato paste are vegetables" and "pizza contains two tablespoons of tomato paste", then we can conclude that "pizza is a vegetable". The same goes for if we can deduce that a sentence is false.

However, if we cannot deduce anything - for example, the set of knowledge we have contains customer information and nothing about pizza or vegetables - then under the open world assumption we have to say that we cannot conclude anything.

With non-monotonic knowledge, anything we know right now can potentially be invalidated. Hence, we cannot safely conclude anything, even if we can deduce true or false from what we currently know.

However, within the database context, and within many computer science applications we prefer to make more definite conclusions. This means assuming what is known as the [closed-world assumption](http://en.wikipedia.org/wiki/Closed_world_assumption): that anything that cannot be shown to be true is false. This means that no explicit declaration of falsehood is needed. In other words, the database of facts that we have is assumed to be complete (minimal), so that anything not in it can be assumed to be false.

For example, under the CWA, if our database does not have an entry for a flight between San Francisco and Helsinki, then we can safely conclude that no such flight exists.

We need one more thing to be able to make definite assertions: [logical circumscription](http://en.wikipedia.org/wiki/Circumscription_%28logic%29). Circumscription is a formalized rule of conjecture. Domain circumscription conjectures that the known entities are all there are. We need to be able to assume that the known entities are all there are in order to reach a definite conclusion.

                                    CWA +             |  CWA +
                                    Circumscription + |  Circumscription +
                                    Monotonic logic   |  Non-monotonic logic
    Can derive P(true)      |   Can assert P(true)    |  Can assert P(true)
    Can derive P(false)     |   Can assert P(false)   |  Can assert P(false)
    Cannot derive P(true)   |   Can assert P(false)   |  Can assert P(false)
    or P(false)

In particular, non-monotonic inferences need this assumption. We can only make a confident assertion if we assume that we have complete information, since additional information may otherwise invalidate our assertion.

What does this mean in practice? First, monotonic logic can reach definite conclusions as soon as it can derive that a sentence is true (or false). Second, nonmonotonic logic requires an additional assumption: that the known entities are all there is.

So why are two operations that are on the surface equivalent different? Why is adding two numbers monotonic, but calculating an aggregation over two nodes not? Because the aggregation does not only calculate a sum but also asserts that it has seen all of the values. And the only way to guarantee that is to coordinate across nodes and ensure that the node performing the calculation has really seen all of the values within the system.

Thus, in order to handle nonmonotonicity one needs to either use distributed coordination to ensure that assertions are made only after all the information is known or make assertions with the caveat that the conclusion can be invalidated later on.

Handling non-monotonicity is important for reasons of expressiveness. This comes down to being able to express non-monotone things; for example, it is nice to be able to say that the total of some column is X. The system must detect that this kind of computation  requires a global coordination boundary to ensure that we have seen all the entities.

Purely monotone systems are rare. It seems that most applications operate under the closed-world assumption even when they have incomplete data, and we humans are fine with that. When a database tells you that a direct flight between San Francisco and Helsinki does not exist, you will probably treat this as "according to this database, there is no direct flight", but you do not rule out the possibility that that in reality such a flight might still exist.

Really, this issue only becomes interesting when replicas can diverge (e.g. during a partition or due to delays during normal operation). Then there is a need for a more specific consideration: whether the answer is based on just the current node, or the totality of the system.

Further, since nonmonotonicity is caused by making an assertion, it seems plausible that many computations can proceed for a long time and only apply coordination at the point where some result or assertion is passed to a 3rd party system or end user. Certainly it is not necessary for every single read and write operation within a system to enforce a total order, if those reads and writes are simply a part of a long running computation.

## The Bloom language

The [Bloom language](http://www.bloom-lang.net/) is a language designed to make use of the CALM theorem. It is a Ruby DSL which has its formal basis in a temporal logic programming language called Dedalus.

In Bloom, each node has a database consisting of collections and lattices. Programs are expressed as sets of unordered statements which interact with collections (sets of facts) and lattices (CRDTs). Statements are order-independent by default, but one can also write non-monotonic functions.


Have a look at the [Bloom website](http://www.bloom-lang.net/) and [tutorials](https://github.com/bloom-lang/bud/tree/master/docs) to learn more about Bloom.

---

## Further reading

#### The CALM theorem, confluence analysis and Bloom

[Joe Hellerstein's talk @RICON 2012](http://vimeo.com/53904989) is a good introduction to the topic, as is [Neil Conway's talk @Basho](http://vimeo.com/45111940). For Bloom in particular, see [Peter Alvaro's talk@Microsoft](http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/Bloom-Disorderly-Programming-for-a-Distributed-World).

- [The Declarative Imperative: Experiences and Conjectures in Distributed Logic](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf) - Hellerstein, 2010
- [Consistency Analysis in Bloom: a CALM and Collected Approach](http://db.cs.berkeley.edu/papers/cidr11-bloom.pdf) - Alvaro et al., 2011
- [Logic and Lattices for Distributed Programming](http://db.cs.berkeley.edu/papers/UCB-lattice-tr.pdf) - Conway et al., 2012
- [Dedalus: Datalog in Time and Space](http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf) - Alvaro et al., 2011

#### CRDTs

[Marc Shapiro's talk @ Microsoft](http://research.microsoft.com/apps/video/dl.aspx?id=153540) is a good starting point for understanding CRDT's.

- [CRDTs: Consistency Without Concurrency Control](http://hal.archives-ouvertes.fr/docs/00/39/79/81/PDF/RR-6956.pdf) - Letitia et al., 2009
- [A comprehensive study of Convergent and Commutative Replicated Data Types](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf), Shapiro et al., 2011
- [An Optimized conflict-free Replicated Set](http://arxiv.org/pdf/1210.3368v1.pdf) - Bieniusa et al., 2012

#### Dynamo; PBS; optimistic replication

- [Dynamo: Amazon’s Highly Available Key-value Store](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) - DeCandia et al., 2007
- [PNUTS: Yahoo!'s Hosted Data Serving Platform](http://scholar.google.com/scholar?q=PNUTS:+Yahoo!'s+Hosted+Data+Serving+Platform) - Cooper et al., 2008
- [The Bayou Architecture: Support for Data Sharing among Mobile Users](http://scholar.google.com/scholar?q=The+Bayou+Architecture%3A+Support+for+Data+Sharing+among+Mobile+Users) - Demers et al. 1994
- [Probabilistically Bound Staleness for Practical Partial Quorums](http://pbs.cs.berkeley.edu/pbs-vldb2012.pdf) - Bailis et al., 2012
- [Eventual Consistency Today: Limitations, Extensions, and Beyond](https://queue.acm.org/detail.cfm?id=2462076) - Bailis & Ghodsi, 2013
- [Optimistic replication](http://www.ysaito.com/survey.pdf) - Saito & Shapiro, 2005
