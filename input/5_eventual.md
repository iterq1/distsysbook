# %chapter_number%. Репликация: протоколы обеспечивающие слабую согласованность

Сейчас, после того как мы расмотрели протоколы которые обеспечивают последовательную согласованность с учетом возрастающего количества обрабатываемых типов отказов, давайте вернемся к пространству возможных опций, которое открывается если мы откажемся от требования последовательной согласованности(без расхождений).

В общем и целом, трудно придумать одно измерение которое будет определять или характиризовать протоколы позволяющие репликам расходится. Большинство таких протоколов обеспечивают высокую доступность и ключевой проблемой является смогут ли конечные пользователи найти гарантии, абстракции, API полезные для их нужд, несмотря на то что реплики могут расходится, когда отказывают узлы или рвется сеть.

Почему слабо согласованные системы менее популярны?

Как я говорил в введении, я думаю что многое в распределенном программировании следует из двух последствий распределенности:

- информация путешествует со скоростью света
- независимые вещи отказывают независимо

Следствием того что скорость распространения информации ограничена, является то что каждый узел воспринимает окружающий мир по-своему. Вычисления на одному узле просты, так как все случается в определенном глобальном и абсолютном порядке. Вычисления на распределенной системе сложны, так как глобального  и абсолютного порядка нет.

Долгое время (десятилетия исследований), мы решали эту проблему введение глобального порядка. Мы обсудили много методов достигающий последовательной согласованности путем создания порядка(с учетом устойчивости к отказам) когда естественного порядка не было.

Конечно, проблема в том что создание порядка крайне затратно. Это зачастую просто невозможно в больших системах работающих в интернете, когда система должна оставатся доступна. Система соблюдающая строгую согласованность ведет себя не как распределенная: она ведет себя как единая система, что плохо для доступности во время разделений.

Кроме того, для каждой операции зачастую большинству узлов необходимо связатся друг с другом - и зачастую не один раз, а дважды(вспомним обсуждение 2PC). Это обычно крайне болезнено для систем которые нуждаются в географической распределенности для обеспечения адекватной производительности для пользователей в разных частях мира.

Так что поведение системы по умолчанию как единого целого возможно не желательно.

Возможно то что мы хотим, это система для которой мы можем писать код без больших затрат на координаци но при это продолжать получать пригодные для наших целей результаты. В замен единственно-верной версии данных, мы принимаем разные реплики с расхождениями между друг другом - это позволит сохранить эффективность и сохранить устойчивость к разделению - и затем мы попробуем найти способ справится с расхождениями каким либо образом.

Согласованность в конечном итоге выражается в следующей идее: узлы которые могут иногда расходится в конечном итоге прийдут к согласию насчет единого значения.

Во всем множестве систем предоставляющем согласованность в конечном итоге, можно выделить два типа архитектур:

*Согласованность в конечном итоге с вероятностными гарантиями*. Этот тип систем может определять конфликты на каком то этапе после их появления, но не дает гарантий что результаты будут эквивалентны результатам корректного порядка исполнения операций. Другими словами, конфликтующие обновления иногда будут перезаписывать новые значения старыми и некотрые аномалии могут проявлятся во время нормального проведения операций(или во время разделения).

В недавние годы,наиболее известная система жертвующая согласованностью на уровне одной копии это Amazon Dynamo, которую я буду обсуждать в качестве системы которая предалагает согласованность в конечном итоге с вероятностными гарантиями.

*Согласованность в конечном итоге со строгими гарантиями*. Этот тип систем гарантирует что результат будет сходится к одному значению эквивалентному полученному при корректной последовательности операций. Другими словами, такие системы не приводят к аномальным результатам; без какой либо координации вы можете создавать реплики сервисов, которые будут коммуницировать любым способом и получать обновления в любом порядке и в конечном итоге они достигнут согласия насчет конечного результата на все время пока они будут видеть одну и туже информацию.

CRDT (сходяющиеся рпелицирующиеся типы данных) это типы данных гарантирующие сходимость к одному и тому же значению несмотря на разделы и задержки в сети и изменение порядка сообщений. Они доказанно сходимы, но ограничены типами данных которые могут быть реализованы как CRDT.

CALM (согласованность как логическая монотонность) гипотеза это альтернативное выражение тех же самых принципов: это уравнивание логической монотонности и сходимости. Если мы можем сделать вывод что чтолибо логически монотонно, тогда мы также можем безопастно запускать это без какой либо координации. Анализ слияний - в частности, применительно к языку программирования Bloom - может быть применен для принятия решений в программировании о том когда и где  использовать координационные техники из строго согласованной системы и когда можно безопастно выполнять операции не пребегая к вычислительно "дорогой" координации.

## Согласование разного порядка операций

Что делает систему не поддерживающей согласованность единной копии? Давайте попробуем сделать более конкретные выводы из нескольких примеров.

Конечно наиболее очевидной характеристикой систем которые не обспечивают согласованности одной копии является, то что они позволяют репликам расходится относительно друг друга. Это означает что нет строгой коммуникации: реплики могут быть отделены друг от друга и даже продолжать быть доступны и записывать данные.

Давайте представим систему из трех реплики, каждая из которых отделена от других. Для примера реплика может быть в другом датацентре или отделена по другим причинам. Каждая реплика остается доступной во время разделения для записи и чтения для некотрого набора клиентов:

    [Клиенты]   - > [A]

    --- Раздел ---

    [Клиенты]   - > [B]

    --- Раздел ---

    [Клиенты]   - > [C]

После некотрого времени, разделение исчезает и реплики начинают обменниваться информацией. Они получают  различные обновления от разных клиентов что приводит к расхождениям - следовательно необходим некотрый способ согласования. Нам бы хотелось бы чтобы все реплики после этого сошлись к одному результату.

    [A] \
        --> [мерж]
    [B] /     |
              |
    [C] ----[мерж]---> результат


Другой путь размышлять о системах с гарантиями слабой согласованности это представить множество клиентов отсылающих сообщения на узла в некотром порядке. Так как у нас нет координационного протокола чтобы обеспечить глобальный единый порядок, сообщения могут быть доставлены в разном порядке на разные реплики:

    [Клиенты]  --> [A]  1, 2, 3
    [Клиенты]  --> [B]  2, 3, 1

Это в сущности причина по которой мы нуждаемся в протоколах координации. Для примера, предположим что мы пытаемся склеить строку за 3 операции:

    1: { операция: concat('Hello ') }
    2: { операция: concat('World') }
    3: { операция: concat('!') }

Тогда, без координации A получит "Hello World!", а B "World!Hello ".

    A: concat(concat(concat('', 'Hello '), 'World'), '!') = 'Hello World!'
    B: concat(concat(concat('', 'World'), '!'), 'Hello ') = 'World!Hello '


Это конечно же некорректно. Опять же, нам бы хотелось чтобы реплики сходились к одному результату.

Держа в уме оба этих примера, давайте взглянем на Amazon's Dynamo в первую очередь чтобы определить базовый уровень и затем обсудим ряд концепций для построения систем со слабой консистентностью, таких как CRDT the CALM теорема.


## Amazon's Dynamo

Архитектура Amazon's Dynamo (2007) это возможно наиболее известный пример системы представляющей слабые гарантии согласованности и являющейся высоко-доступной системой. Это основа для многих промышленных систем таких как LinkedIn's Voldemort, Facebook's Cassandra и Basho's Riak.

Dynamo это ключ-значение хранилище обеспечивающее согласованность в конечном итоге и высокую доступность. Ключ-значение хранилище напоминает огромную хеш-таблицу: клиент может установить некоторое значение по ключу используя `set(key, value)` и получить некоторое значение по ключу используя `get(key)`. Dynamo кластер содержит N частей узлов; каждый узел отвечает за определенный набор ключей.

Dynamo разработана с приоритетом доступности над согласованностью; согласованность на уровне одной активной копии не гарантируется. Реплики могут расходится относительно друг друга когда значения записываются; во время чтения по ключу, происходит фаза согласования во время которой различия разных реплик обьединяются перед тем как возвратить результат клиенту.

Для многих отраслей бизнесса Amazon, более важно избегать простоев нежели держать данные в полной консистентности, так как отключение может привести к бизнесс-потерям и утрате доверия клиентов. Более того, если данные не особо важные, тогда системы с слабой согласованностью могут предоставлять лучшую производительность и более высокую доступность с более низкими затратами нежели традиционные RDBMS.

Dynamo это полная архитектура системы, в которой необходимо расмотреть много различных частей некоторые из которых выходят за рамки задачи репликации; особенно, как запись диспатчеризируется между узлами и как происходит запись на несколько узлов.

    [ Клиент ]
        |
    ( Отображение ключей в узлы )
        |
        V
    [ Узел A ]
        |     \
    ( Синхронная часть репликации: минимум надежности )
        |        \
    [ Узел B]  [ Узел C ]
        A
        |
    ( Определение конфликта; асинхронная часть репликации:
      обеспечивает востановление разделенных / упавших узлов )
        |
        V
    [ Узел D]

После того как мы взглянем как запись принимается после иницирования клиентов, мы посмотрим как обнаруживаются конфликты и на асинхронную часть репликации. Это часть необходима, из-за дизайна высоко-доступных решений, в которых узлы могут быть временно недоступны(изза отказа или разделения). Синхронизация реплик обеспечивает довольно быстрое приведение реплики к актуальному состоянию даже после отказа.

### Согласованное хэширование(Consistent hashing)

Записываем мы или читаем, первое что должно произойти мы должны определить где данные должны находится в системе. Это требует некотрого отображение ключей в узлы на которых они хранятся.

В Dynamo, ключи отображаются в узлы используя технику хеширования известную как [согласованное хеширование](https://github.com/mixu/vnodehash) (которое я не буду обсуждать детально). Главная идея это что ключи могут быть отображены в набор узлов при помощи простых вычислений на клиенте. Это значит что клиент может обнаружить ключи без запроса к системе для определения расположения ключа; это экономит системные ресурсы так как хеширование во много раз быстрее чем вызов удаленной процедуры.

### Частичный кворум

После того как мы разобрались как ключ должен хранится, мы должны понять как хранится значение. Это синхронная задача; причина по которой нам надо записывать немедленно значение на несколько узлов это предоставление высокого уровня надежности (например для защиты от немедленного отказа узла).

Так же как и Paxos или Raft, Dynamo использует кворумы для репликации. Однако Dynamo кворумы нестрогие(основанные только на часте узлов) в отличии от строгих(основанных на большинстве) кворумов.

Неформально, строгие системы кворумов это системы кворумов с таким свойством что любые два кворума в системе пересекаются. Требование большинства голосов для обновления перед его принятием гарантирует что только одна версия истории изменений будет признаной для каждого мажоритарного кворума так как каждый такой кворум будет пересекатся с другим хотя бы в одном узле. На это свойство опирается к примеру Paxos.

Частичный кворум не удовлетворяет этому свойству; это означает что большинство не требуется и различные подмножества кворума могут содержать различные версии одних и тех же данных. Юзер может выбирать число узлов для записи и чтения:

- пользователь может выбрать некотрое число W-из-N узлов требуемое для того чтобы запись была успешна; и
- пользователь может определить число узлов (R-из-N) которым необходимо контактировать при чтении.

`W` и `R` определяет число узлов которые должны быть вовлечены в процесс записи и чтения. Запись с использованием большего числа узлов будет более медленной но повысит вероятность того что значение не будет потеряно; чтение с большего числа узлов повышает вероятность того что прочитанное значение будет актуально.

Типичная рекомендация это `R + W > N`, потому что это означает что кворумы для чтения и записи пересекаются хотя бы в одном узле - что делает менее вероятным что устаревшее значение будет прочитано. Обычная конфигурация это `N = 3` (то есть всего 3 рпелики для каждого значения); это означает что юзер может выбирать между:

     R = 1, W = 3;
     R = 2, W = 2 или
     R = 3, W = 1

В более общем плане `R + W > N`:

- `R = 1`, `W = N`: быстрое чтение, медленная запись
- `R = N`, `W = 1`: быстрая запись, медленное чтение
- `R = N/2` and `W = N/2 + 1`: хорошо и для того и для того

N редко больше 3, так как хранение большого числа копий может быть дорогостояще для большого количества данных!

Как я упомянал ранее, публикация Dynamo  вдохновила многие подобные системы. Они все используют репликацию на основе частичных кворумов, но с другими N, W и R по умолчанию:

- Basho's Riak (N = 3, R = 2, W = 2 по умолчанию)
- Linkedin's Voldemort (N = 2 or 3, R = 1, W = 1)
- Apache's Cassandra (N = 3, R = 1, W = 1)

Так же есть другой ньюанс: когда отправляется запрос на запись или чтение, все N узлов опрашиваются (Riak), или только некоторое число узлов - минимальный кворум (то есть R или W; Voldemort). Отправка всем более быстра и менее чувствительна к задержкам(так как можно ждать ответ только R или W узлов из N) но менее эффективен, Отправка запроса только минимуму узлов более чувствительна к задержкам(так как задержка в общении с одним узлом приведет к задержке всей операции) но более эффективно (меньше сообщений / соединений в целом)

Что случится когда кворумы записи и чтения перекрываются то есть (`R + W > N`)? В частности, зачастую говорят что в  результате мы получим "строгую согласованность".

### R + W > N это тоже самое что и "строгая согласованность"?

Нет.

Для этого нет оснований: система где `R + W > N` может определять конфликты записи и чтения, так как кворумы для записи и чтения пересекаются. Например хотя бы один узел будет обоих кворумах:

       1     2   N/2+1     N/2+2    N
      [...] [R]  [R + W]   [W]    [...]

Это гарантирует что предыдущая запись будет видна для последующих чтений. Однако, это так только если число узлов N никогда не будет менятся. Следовательно, Dynamo не сдерживает этих гарантий, потому что в Dynamo кластер может быть изменен если узлы откажут.

Dynamo разработана чтобы быть всегда доступной для записи. Она содержит который обрабатывает отказ узлов путем добавления другого не связанного сервера в набор узлов отвественных за хранение определенных ключей пока другой узел не работает. Это означает что кворум не гарантирует пересечений всегда. Даже `R = W = N` не будет этого гарантировать, так как пока размер кворума N узлы в кворуме могут менятся изза отказов. В частности, во время раздела, если достаточное число узлов не может быть достигнуто, Dynamo будет добавлять новые узлы из несвязанных с исходными но доступных узлов.

Кроме того, Dynamo не обрабатывает разделы так же как система с строгой согласованностью, а именно: она позволяет записывать данные по обе стороны раздела сети, это означает что система не действует так как если бы она не была распределенной. Поэтому называть `R + W > N` "строго согласованным" ошибочно; гарантии только лишь вероятностные - что не подходит для строго согласованной системы.

### Определение конфликтов и чтение исправленых записей

Системы которые которые позволяют репликам расходится должны иметь способ в конечном итоге согласовать два различных значения. Как кратко упоминалось в ходе обсуждения подходов основанных на частичном кворуме, один из способов это использовать определение конфликтов во время чтения а затем применить какой-либо алгоритм разрешения конфликтов. Но как это сделать?

В общем случае, Iэто можно сделать путем отслеживание причинноследственных связей между кусочками данных через сохранненые в них метаданные. Клиенты должны получить метаданные когда они читают данные из системы и они должны вернуть назад значение метаданных когда они записывают данные в базу данных.

Мы уже встречались с методом который делает это: векторные часы могут быть использованы для представления истории некотрого значения. В самом деле, именно их использует оригинальная архитектура Dynamo для определения конфликтов.

Однако, использование векторные часы не единственная альтернатива. Если взглянуть на архитектуру многих промышленных систем, можно понять немного о том как они работают глядя на метаданные которые они отслеживают.

*Без метаданных*. Когда система не отслеживает метаданные, и всегда возвращает только значение(с помощью клиентского API), у нее нет возможности как либо специально обрабатывать конкурентные записи. Общее правило в таких системах "last writer wins": другими словами, если два записывающих клиента пишут в одно и тоже время, только значение от более медленного клиента будут сохранятся.

*Временные метки*.  Формально, значение с более поздней временной меткой "выигрывает". Однако, если время не синхронизированно точно могут происходить многие странные случаи когда новое значение(из части системы с отстающим временем) будет затерто более старым. Facebook Cassandra это реализация архитектуры Dynamo которая использует временные метки вместо векторных часов.

*Номера версий*. Номера версий могут помочь избежать могих проблем использования временных меток. Однако для отслеживания нескольких причинно-следственных связей недостаточно номеров версий и необходимы векторные часы.

*Векторные часы*. Используя векторные часы,  конкурентные и устаревшие обновления могут быть обнаружены. Выполнение исправления при чтении также становится возможным, хотя в некотрых случаях(конкурентные изменения) необходимо спрашивать у клиента значение. Это так потому что если изменения паралельные и мы не знаем ничего больше о данных(как в нашем случае когда мы работаем с хранилищем ключ-значение), тогда лучшей политикой будет спросить нежели отбросить данные произвольно.

Когда происходит чтение значения, клиент контактирует с `R` из `N` узлов и опрашивает их о последнем значении для ключа. Далее берет все их ответы и отбрасывает значения которые строго более старые(для этого используются векторные часы). Если остается только одна уникальная пара векторные часы + значение, тогда возвращается она. Если остается несколько таких пар(которые редактировались конкурентно), тогда возвращаются все они.

Из этого очевидно что чтение исправленных записей может возврашать множество значений. Это означает что клиент / приложение должно уметь время от времени обрабатывать случаи выбирая значение на основе конкретного критерия в каждом отдельном взятом случае.

В дополнение, ключевой компонент промышленных систем с векторными часами это то что часы не могут расти вечно - так что необходимо иногда собирать мусор безопастным способом чтобы не нарушить требования отказоустойчивости хранилища.

### Синхронизация реплик: gossip и деревья Меркла

При условии что Dynamo-архитектура устойчива к падениям узлов и разделениям сети, она должна уметь пересоединять кластер после разделения или заменять упавший узел или присоединять востановившийся.

Синхронизация реплик используется для обновления реплик до актуального состояния после отказа и для периодической синхронизации реплик между друг другом.

Gossip это вероятностный способ для синхронизации реплик. Это паттерн коммуникации (то есть способ которым узел общается с узлом) не детерминирован заранее. Вместо этого, узлы имеют некотрую вероятность `p` того что узел попытается синхронизироватся с другими. Каждые `t` секунд, каждый узел выбирает узел с которым будет коммуницировать. Это обепечивает дополнительный механизм за пределами синхронной части репликации (такой как частичный кворум записи) который приводит копии в актуальное состояние.

Gossip это масштабируемое и без единой точки отказа, но предоставляющее только вероятностные гарантии.

Для того чтобы сделать обмен информацией во время синхронизации реплик эффективных, Dynamo использует технику под названием деревья Меркла, которые я не буду описывать в деталях. Ключевой идея это то что данные могут быть захешированы на нескольких уровнях детализации: хеш всего контента, хеш половины ключей, четверти и так далее.

Поддерживая этот довольно детализированный хеш, узлы могут сравнивать данные которые хранят более эффективно чем сравнение в лоб. После того как узлы определили какие узлы содержат различные значения они могут обменится необходимой информацией чтобы привести реплики в актуальному состоянию.

### Dynamo на практике: вероятностное ограничение устаревания (PBS)

Это в значительной степени охватывает архитектуру Dynamo:

- согласованное хеширование для определения расположения ключа
- частичный кворум для записи и чтения
- определение конфликтов и чтение исправлений используя векторные часы
- gossip для синхронизации реплики

Как можно было бы охарактеризовать поведение такой системы? Довольно недавняя публикация Bailis (2012) описывает подход названный  [PBS](http://pbs.cs.berkeley.edu/) (вероятностное ограничение устаревания) использует симуляцию и сбор данных о промышленных системах чтобы охарактеризовать ожидаемое поведение подобной системы.

PBS оценивает степень несогласованности используя информацию о уровне анти-энтропии (gossip), сетевых задержек и задержек локальной обработки чтобы определить ожилаемый уровень согласоваанности чтения. Этот прием реализован в Cassandra, где временная информация скомбинирована на разных сообщениях и оценка расчивается на основе этой информации сэмулированной методом Монте-Карло.

Основываясь на публикации, во время нормальных операций(без каких либо сетевых и прочих проблем) время согласования данных зачастую намного меньше и можно читать согласованные данные за десятки-сотни миллисекунд. Таблица ниже показывает количество времени требуемое для 99.9% вероятности прочтения согласованных данных при различных настройках `R` и `W`(получена в результате анализа оптыных данных времени синхронизации из LinkedIn(SSD и 15k RPM disks) и Yammer) :

![из публикации о PBS](./images/pbs.png)

Для примера, при переходе от `R=1`, `W=1` к `R=2`, `W=1` в Yammer продолжительность случаев несогласованности сокращается от 1352 мс до 202 мс - при удержани времени задержки при чтении на низком уровне (32.6 ms) что быстрее чем в режиме строгого кворума (`R=3`, `W=1`; 219.27 ms).

Для большего погружения, смотрите [PBS сайт](http://pbs.cs.berkeley.edu/) и саму публикацию.

## Программирование в неупорядоченной манере

Давайте вернемся назад к примерам типов проблем которые нам бы хотелось решить. Первый сценарий содержит 3 различных сервера с разделением; когда разделение устранено, мы хотим чтобы сервера сошлись к одному и тому же значению. Amazon's Dynamo делает это возможным путем чтения значений с `R` из `N` узлов и после выполняя согласование значения.

Во втором примере, у нас содержится более специфичная операция - соединение строк. Оказывается что мы не знаем технику сделать обьединение строк без учета порядка операций (то есть без дорогой координации). Однако, иммеются операции которые могут быть применены безопастно в любом порядке, там где простая запись не может гарантировать корректность. Как пишет Pat Helland:

> ... Работа основанная на операциях может быть коммутативной (с правильными операциями и правильной семантикой) в то время как простая семантика ЗАПИСЬ/ЧТЕНИЕ не поддается обеспечению коммутативности.

Для примера, возьмем систему которая реализует простой механизм оплаты с операциями `дебит` и `кредит` двумя способами:

- используя ячейку данных с операциями `запись` и `чтения`
- используя целочисленный тип с встроенными операциями `дебит` и `кредит`

Последняя реализация знает больше о внутреннем устройстве типа данных и может сохранять итог  операций несмотря на то что порядок операций может быть изменен. Дебит или кредит могут быть применены в любом порядке и получится один и тот же результат:

    100 + кредит(10) + кредит(20) = 130 and
    100 + кредит(20) + кредит(10) = 130

 Однако, запись фиксированных значений не может быть переупорядочена: если запись будет переупорядочена то тогда она перепишет другую:

    100 + запись(110) + запись(130) = 130 but
    100 + запись(130) + запись(110) = 110

Давайте возьмем пример из начала этой главы но используем другие операции. В этом сценарии, клиенты шлют сообщения двум узлам, которые видят операции в разном порядке:

    [Клиенты]  --> [A]  1, 2, 3
    [Клиенты]  --> [B]  2, 3, 1

Вместо обьеднения строк, Instead of string concatenation, преположим что мы ищем наибольшее значение (то есть max()) для множества целых чисел. Сообщения 1, 2 и 3 таковы:

    1: { операция: max(предыдущий, 3) }
    2: { операция: max(предыдущий, 5) }
    3: { операция: max(предыдущий, 7) }

То есть, без координации мы придем к одному и тому же значению - 7:

    A: max(max(max(0, 3), 5), 7) = 7
    B: max(max(max(0, 5), 7), 3) = 7

В обоих случаях, обе реплики видели обновления в разном порядке, но объединение результатов привело к получению одного и того же значения независимо от порядка. Результат сошелся в обоих случаях потому что была использована процедура обьединения (`max`).

Вполне веротяно что мы не можем написать процедуру обьединения для всех типов данных. В Dynamo, значение это бинарный файл, так что лучшее что можно сделать это просить приложение разрешить конфликты после каждого такого случая.

Однако, если мы знаем что данные более специфичного вида, мы можем обрабатывать возможные типы конфликтов. CRDT это структуры данных разработанные для предоставления типов данных которые всегда сходятся к одному значению если они получают одинковый набор изменений (без учета порядка).

## CRDT: Сходящиеся реплицируемые типы данных

CRDTs основывается на знаениях о свойствах коммутативности и ассоциативности специфических операций над специфицическими типами данных.

Для того чтобы набор операций сходился к определенному значению в ситуации когда реплики коммуницируют время от времени, операции должны быть порядко-независимыми и не чувствительными к дупликации/переотправке сообщений. Таким образом, операции должны быть:

- Ассоциативными (`a+(b+c)=(a+b)+c`), то есть перегруппировки должны не изменять результата
- Коммутативными (`a+b=b+a`), то есть порядок применения должен быть неважен
- Идемпотентными (`a+a=a`), то есть повторное применение не должно влиять на результат

Это возврашет нас к структурам которые уже известны в математике; они известны как объединяемые или сходящиеся [полурешетки](http://en.wikipedia.org/wiki/Semilattice).

[Полурешетка](http://en.wikipedia.org/wiki/Lattice_%28order%29) это частично упорядоченный набор с единственной верхней границей и единственной нижней границей. Полурешетка напоминает обычную решетку но с единственной верхней и нижней границей. Обьединяемые полурешетки имеют только верхнюю границу, а сходящиеся только нижнюю.

Любой тип данных который может быть выражен как полурешетка может быть реализован как структура данных с гарантиями сходимости. Для примера, подсчет  `max()` набора значений всегда будет возврашать одно и то же значение независимо от порядка получаемых значений, всегда пока значения будут поступать, потому что операция `max()` ассоциативна, коммутативна, и идемпотентна.

Для примера, здесь две полурешетки: первая отображает набор где оператором обьединения служит функция `union(items)`, во второй мы имеем строго возрастающий счетчик с оперетором объединения `max(values)`:

       { a, b, c }              7
      /      |    \            /  \
    {a, b} {b,c} {a,c}        5    7
      |  \  /  | /           /   |  \
      {a} {b} {c}            3   5   7

С типами данных которые могут быть выражены полурешетками, мы можем иметь реплики которые коммуницирует любым способом и получают обновления в любом порядке, и они будут в конечном счете сходится к конечному результату, до тех пор пока они получают одну и ту же информацию. Это наиболее сильное свойство которое мы можем гарантировать, до тех пока мы выполняем предпосылки.

Однако, выражение типов данных в виде полурешеток зачастую требует некотрого уровня интерпретации. Многие типы данных имеют операции которые не подходят для того чтобы быть выражеными порядко-независимыми. Для примера, добавление элемента в множество ассоциативно, коммутативно и идемпотентно. Однако, если мы также позволяем удалять элементы тогда необходим способ разрешать конфликтуюшие операции вроде `добавить(A)` и `удалить(A)`. Что означает удалить элемент если этот элемент никогда не был добавлен в локальную реплику?  Решение этого вопроса должно быть определено в порядко-независимой манере, и есть несколько различных вариантов с разными компромисами.

Это означает что несколько похожих типов данных имеют более узкоспециализированную реализацию как CRDT которая идет на различные компромиссы с упорядоченностью чтобы разрешать конфликты в порядко-независимым способом. В противоположность ключ-значение хранилищу которая оперирует простыми ячейками (то есть значениями служат файлы непрозрачной структуры с точки зрения системы), при использовании CRDT необходимо использовать правильный тип данных чтобы избежать аномалий.

Несколько примеров различных типов данных определенных как CRDT:

- Счетчики
  - Постоянно возрастающий счетчик (функция объединения = max(values); содержимое = single integer)
  - Положительно-отрицательный счетчик (содержит два возрастающих счетчика, один для прибавлений, другой для вычитаний)
- Ячейки
  - "Last Write Wins" - ячейки (временные метки или номера версий;функция объединения = max(ts); содержимое = blob)
  - Ячейка с множественным значением (векторные часы; функция объединения = take both)
- Множества
  - Только увеличивающиеся множество (функция объединения = union(items); сожержимое = set; элементы не удаляемы)
  - Двух-фазное множество (содержит два множества, одно для добавленных элементов, и другое для удаленных; элементы можно удалить и добавить один раз)
  - Уникальное множество (оптимизированная версия двух-фазного)
  - "Last write wins" множество (функция объединения = max(ts); сожержимое = set)
  - Положительно-негативное множество (содержит PN-счетчик для каждого элемента)
  - Observed-remove множество
- Графы и техтвые последовательности(см. публикацию)

Для обеспечения операций без аномалий, ты должен найти правильный тип данных для своего приложения - для примера, если ты значешь что ты будешь удалять один элемент только один раз - двух-фазное множество будет отлично работать; если ты будешь только добавлять элементы тогда сгодится и только возрастающее множество.

Не все типы данных имеют известные реализации CRDT, но созданы CRDT имплементации для булевых констант, счетчиков, множеств, регистров, графов (2011) [ислледовательская публикация от Шапиро и других](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf).

Интересно, что реализация ячейки напрямую соотвествует реализациям хранилищ ключ значение: last-write-wins ячейка использует временные метки и просто сходится к значению с наибольшей меткой времени; ячейка с множественным значением соотвествует стратегии сохранения и разрешения конфликтующих записей Dynamo. Для более глубокого погружения я рекомендую взглянуть на публикацию в секции "для дальнейшего чтения" этой главы.

## CALM теорема

CRDT основаны на осознание того факта что структуры данных выражженные как полурешетки сходятся. Но программирование это не только изменение состояния, если только вы не разрабатываете хранилище данных.

Несомненно, порядко-независимость это важное качество для сходимости любых вычислений: если порядок в котором получаются данные влияет на результат вычислений, нет способа выполнять вычисления без гарантии определенного порядка.

Однако, существуют многие модели программирования в которых порядок операторов не играет важной роли. Для примера, в [MapReduce model](http://en.wikipedia.org/wiki/MapReduce), и Map и Reduce задачи определяют как задачи обработки кортежей без внутреннего состояния которые необходимо запустить на наборе данных. Конкретные решения о том как и в каком порядке данные должны поступать в задачи не определяются явным образом, вместо этого планировшик сам отвечает за распределение задач между узлами в кластерах и порядком их запуска.

Похожим образом, в SQL мы только записываем запрос но не определяем как его выполнять. Запрос это простая декларативная запись задачи и работой оптимизатора запросов является выяснить эффективный способ выполнения запроса (распределив выполнение между машинами, базами и таблицами).

Конечно, эти модели программирования не такие универсальные как ящыки общего назначения. MapReduce задачи должны быть выражены как чистые функции в ациклическом пути исполнения программы; SQL команды могут выполнять довольно сложные вычисления но многие вещи довольно трудно представимы в них.

Однако, это два простых примера которые показывают что есть много задач обработки информации которые поддаются выражению в декларативном языке в котором явно не указывается порядок. Модель программирования которая выражает желаемый результат без явного указания порядка вычислений(оставляя его оптимизатору) имеют порядко-независимую семантику. Это означает что программы могут быть выполнены без координации, поскольку они зависят от входных данных но не зависят от порядка получаемых данных.

Ключевая идея что такие программы *могут быть* безопастными при выполнении без координации. Без явного правила которое характеризует то что является безопастным для выполнения без координации, а что нет, мы не можем реализовать программу оставаясь уверенным, что результат работы программы корректен.

Именно об этом говорит CALM теорема. CALM теорема  основана на осознании связи между логической монотонностью и полезной для использования формой согласованности в конечном итоге (то есть слияния/сходимости). Она утверждает что логически монотонная программа будет согласованной в конечном итоге.

Следовательно, если мы знаем что некотрые вычисления логически монотонны, значит мы знаем что данные вычисления безопастно запускать без координации.

Для лучшего понимания этого, мы должны увидеть разнницу между логически монотонными вычислениями и [не логически монотонными](http://plato.stanford.edu/entries/logic-nonmonotonic/).

<dl>
  <dt>Монотонность</dt>
  <dd>Если утверждение `φ` является следствием из множества предпосылок `Γ`, тогда оно может быть выведено из любого множества предпосылок `Δ` расширяющего `Γ`</dd>
</dl>

Большинство стандартных логических структур монотонны: любые выводы сделанные в рамках логики первого порядка, при дедуктивном выводе, не могут быть опровергнуты новой информацией. Не монотонная логика это система в которой данное свойство не сдерживается - другими словами, некотрые выводы в такой системе могут быть опровергнуты новыми данными.

В сообществе разработчиков исскуственного интеллекта, не монотонная логика ассоциируется с [опровергаемыми расуждениями](http://plato.stanford.edu/entries/reasoning-defeasible/) - расуждениями, в которых предположения сделанные на части информации могут быть опровергнуты новой информацией. Для примера, если вы узнаете что Твити это птица, вы предположите что Твити умеет летать; но если вы позже узнаете что Твити это пингвин тогда вам приедется пересмотреть свое предположение.

Монотонность касается отношений между предпосылками (или фактами о окружающей среде) и заключениями (или утверждениями об окружающей среде). В монотонной логике мы знаем что наши результаты не пересматриваемы: [монотонные](http://en.wikipedia.org/wiki/Monotonicity_of_entailment) вычисления не нужнаются в перевычислениях или координации; ответ становится все более точным с течением времени. Однажды узнав что Твити это птица (и что мы рассуждаем с использованием монотонной логики), мы можем безопастно заключить что Твити может летать и что ничего что мы узнаем не заставит нас отказатся от этого заключения.

В то время как любые вычисления что вычисляют человеко-читабельный результат могут быть интерпретированы как утверждения об окружающем мире, определение является ли вычисление в программе исполняемой на фон-Нейманновской машине монотонным трудно, потому что не совсем очевидны отношения между фактами и утверждениями и являются ли эти отношения монотонными.

Однако, существует некотрые модели программирования которые можно определить как монотонные. Например, [реляционная алгебра](http://en.wikipedia.org/wiki/Relational_algebra) (теория лежащая в основе SQL) и [Datalog](http://en.wikipedia.org/wiki/Datalog) предоставляющие высокоуровневые языки которые имеют хорошо понятные интерпретации.

Оба(Datalog и реляционная алгебра - даже с рекурсией), как известно, монотонны. Более конкретно, вычисления выраженные с использованием определенного набора базовых операторов - выборка, проекция, естественное соединение, декартово произведение, объединение и рекурсивный Datalog без отрицаний) - монотонны, и становятся не монотонными при добавлении более продвинутых операторов (отрицание, вычитание, деление, квантор всеобщности, группировка).

Это означает что вычисления выраженные с использованием значительного количества операторов (таких как map, filter, join, union, intersection) в твоей системе логически монотонны; любые вычисления использующие эти вычисления также монотонны и таким образом их можно безопастно запускать без координации. Выражения которые используют отрицания или группировки, напротив делают невозможным запуск таких вычислений без координации.

Это важно для понимания связи между немонотонностью и операциями которые очень ресурсоемки при апуске в распределенной системе. Конкретно, и *распределенная группировка* и *протоколы координации* считаются одной из форм отрицания. Как Joe Hellerstein [писал](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf):

> Для обеспечения достоверности отрицательного предиката в распределенной среде, стратегия вычисления должна начать "подсчет с 0", чтобы определить пустоту, и ждать пока распределенный процесс подсчета определится как завершенный. Группировка это обобщение этой идеи.

и:

> Эта идея может быть расмотрена с другой стороны также хорошо. Протоколы координации это сами аггрегатами, так как они представляют из себя голосования: двух-фазный коммит требует единодушного голосования, Paxos требует большинство голосов, и Византийский протокол требует 2/3 большинства. Ожидание требует подсчета.



Если, мы можем выразить наши вычисления способом в котором возможно проверить монотонность, тогда мы можем выполнить статический анализ всей программы и определить участки программы которые будут согласованны в конечном итоге без координации (монотонные участки) - и которые не соотвествуют этому требованию (не монотонные).

Заметим что это требует других типов языков, поскольку эти выводы сложно сделать для традиционных языков, где последовательности, выборки и итерация встроены в само ядро. Это причина по которой был разработан язык Bloom.


## Для чего может быть полезна не монотонность вычислений?

Разница между монотонность и не монотонностью крайне интересна. Для примера, сложение двух числе монотонно, но подсчет аггрегации двух узлов содержащих числа не монотонно. В чем же разница? Первое это вычисление (сложение двух чисел), а второе это утверждение (расчет аггрегата).

В чем разница между утверждением и вычислением? Давайте расммотрим запрос "Эта пицца овощная?". Для ответа, мы должны вникнуть в суть: когда приемлимо сделать вывод, что что-либо верно(или не верно)?

Существует несколько возможных ответов, каждый вытекает из разного набора допущений относительно информации что у нас есть и того как мы должны действовать в соотвествии с ней - и мы приходим к пониманию что мы можем принять различные ответы в различных контекстах.

В повседневных рассуждениях, мы делаем то что известно как[Предположение об открытости мира](http://en.wikipedia.org/wiki/Open_world_assumption): мы допускаем что мы не знаем всего, и следовательно не можем делать заключение изза недостатка у нас знаний. То есть любое утверждение может быть истинным, ложным, или может быть неизвестно истинно оно или нет.

                                    OWA +             |  OWA +
                                    Монотонная логика   |  Не монотонная логика
    можем вывести P(истина)      |  Можем утверждать P(true)    |  Не можем утверждать P(true)
    можем вывести P(false)     |   Можем утверждать P(false)   |  Не можем утверждать P(true)
    Не можем вывести P(true)   |   Неизвестно               |  Неизвестно
    и P(false)

Когда делается предположение об открытости мира, мы можем безопастно утверждать только то что мы можем вывести из известной нам информации. Наши знания о мире считаются неполными.

Давайте сначала взглянем на случай когда мы знаем, что наши рассуждения монотонны. В этом случае, любое(потенциально не полное) знание которое у нас есть мы не может сделать недействительным, узнав чтото новое. Так если мы вывели что предложение верно основываясь на некотрой дедукции, такой как "то что содержит, две столовых ложки томатной пасты является овощным" и "пицца содержит две столовых ложки томатной пасты", тогда мы можем заключит что "пицца овощная. То же самое верно и для случая если мы сможем дедуктивно показать что утверждение ложно.

Однако, Если мы не можем применить дедукцию - для примера, набор наших данных содержит информацию о клиентах и ничего о пицце или овощах - тогда при условии предположения открытого мира мы должны заключить что не можем сделать вывод.

С немонотонным знанием, все что мы узнаем может быть признано недействительным в будущем. Следовательно, мы не можем безопастно делать какие либо выводы, даже если мы сделали дедуктивный вывод из текущих знаний.

Однако, в контексте баз данных, и в рамках многих приложений информатики мы предпочтем сделать более определенные заключения. Это означает допущение известное как [предположении о закрытом мире](http://en.wikipedia.org/wiki/Closed_world_assumption): что чтолибо не может быть доказано как истинное - ложное. Это означает что нет нужды в явном объявлении ложности. Другими словами, база данных - это факты которые мы будем считать полными(минимальными), следовательно они не могут быть ложными.

Для примера, в ПЗМ, если наша база данных не содержит в себе перелетов между Сан-Франциско и Хельсинки, значит мы можем заключить что такого перелета нету.

На необходимо больше способов для того чтобы делать определенные утверждения: [логической ограничение](http://en.wikipedia.org/wiki/Circumscription_%28logic%29). Ограничение это формализованное правило гипотезы. Область ограниченная гипотезой предполагает что все известные сущности содержатся в ней. Мы должны допускать что известные сущности содержатся в области гипотезы чтобы достичь определенного вывода.

                                    CWA +             |  CWA +
                                    Ограничение + |  Ограничение +
                                    Монотонная логика   |  Не монотонная логика
    Можем вывести P(true)      |   Можем утверждать P(true)    |  Можем утверждать P(true)
    Можем вывести P(false)     |   Можем утверждать P(false)   |  Можем утверждать P(false)
    Cannot вывести P(true)   |   Можем утверждать P(false)   |  Можем утверждать P(false)
    или P(false)

В частности, не монотнные выводы нуждаются в этом допущении. Мы можем сделать уверенное устверждение если мы допускаем что мы имеем полную информацию, так как дополнительная информация может сделать недействительными наши утверждения.

Что это хначит на практике? Во первых, монотонная логика может достичь определенного заключения так скоро как станет возможным вывести что утверждение истинно(или ложно). Во вторых не монотнная логика требует дополнительного допущения что все необходимые сущности для вывода у нас уже есть.

Так почему 2 операции который на первый взгляд эквивалентны на самом деле отличаются? Почему сложение двух чисел монотонно а аггрегация данных с двух узлов нет? Потому что аггрегация не только считает сумму но и также утверждает что есть все необходимые значения. И единственный способ гарантировать это - это координировать узлы и обеспечивать чтобы узлы выполняли вычисления только когда им видна вся информация в системе.

Таким образом, в целях обработки не моннотонности необходимо либо использовать распределенную кординацию для обеспечения того что утверждения сделаны после того как вся информация стала известна либо делать утверждения с оговоркой что в дальнейшем они могут быть отменены.

Обработка не монотонности важна в целях выразительности. Это сводится к возможности выражать не монотонные вещи; для примера, удобно когда вы можете сказать что абсолютное значение колонки - X. Система должна определять что этот тип вычислений требует глобальной координации границ для того чтобы обеспечивать полноту видимых в системе сущностей.

Чисто монотонные системы редки. Кажется что большая часть приложений работает в предположении закрытого мира даже когда она имеет неполные данные и мы, люди, свыклись с этим. Когда база данных говорит что прямого рейса из Сан-Франциско до Хельсинки не существует, вы будете предполагать что "в соответсвии с этой базой данных, прямого рейса нет", но вы исключите возможность что такой рейс может существовать.

В реальности, эта проблема приходит только когда реплики расходятся (во время разделений или изза задержекво время нормальных операций). Толгда необходимо более частное рассмотрение: ответ основан только на инфмормации с реплики или на информации со всей системы.

В дальнейшем, поскольку немонотонность это причина того что было сделано утверждение, кажестся правдоподобным, что многие вычисления могут продолжать работать в течении длительного времени и применять координацию только в местах где результат или утверждение попадает пользователю или в стороннюю систему. Конечно не является необходимым обеспечивать абсолютный порядок для всех чтений и записей, если эти операции просто элементы в длинной цепочке вычислений.

## Язык Bloom

[Язык Bloom](http://www.bloom-lang.net/) это язык разработанный чтобы использовать CALM теорему. Это Ruby DSL который имеет формальную основу в темпоральной логике языка программирования названного Dedalus.

В Bloom, каждый узел имеет базу данных содержащих коллекцию или решетку. Программы выражаются как наборы неупорядоченных объявлений который взаимодействуют с коллекциями(наборы фактов) и решетками(CRDT). Объявления порядко независмы по умолчанию, но вы также можете писать не монотонные функции.


Посмотрите на [Bloom сайт](http://www.bloom-lang.net/) и [учебник](https://github.com/bloom-lang/bud/tree/master/docs) чтобы узнать больше о  Bloom.

---

## Дальнейшее чтение

#### CALM теорема, анализ слияний и Bloom

[речь Joe Hellerstein @RICON 2012](http://vimeo.com/53904989) хорошее введение в тему, как есть [речь Neil Conway  @Basho](http://vimeo.com/45111940). Для Bloom в частности, смотрите [речь Peter Alvaro @Microsoft](http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/Bloom-Disorderly-Programming-for-a-Distributed-World).

- [The Declarative Imperative: Experiences and Conjectures in Distributed Logic](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf) - Hellerstein, 2010
- [Consistency Analysis in Bloom: a CALM and Collected Approach](http://db.cs.berkeley.edu/papers/cidr11-bloom.pdf) - Alvaro et al., 2011
- [Logic and Lattices for Distributed Programming](http://db.cs.berkeley.edu/papers/UCB-lattice-tr.pdf) - Conway et al., 2012
- [Dedalus: Datalog in Time and Space](http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf) - Alvaro et al., 2011

#### CRDT

[речь Marc Shapiro @ Microsoft](http://research.microsoft.com/apps/video/dl.aspx?id=153540) хорошая отправная точка для понимания CRDT.

- [CRDTs: Consistency Without Concurrency Control](http://hal.archives-ouvertes.fr/docs/00/39/79/81/PDF/RR-6956.pdf) - Letitia et al., 2009
- [A comprehensive study of Convergent and Commutative Replicated Data Types](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf), Shapiro et al., 2011
- [An Optimized conflict-free Replicated Set](http://arxiv.org/pdf/1210.3368v1.pdf) - Bieniusa et al., 2012

#### Dynamo; PBS; оптимистическая репликация

- [Dynamo: Amazon’s Highly Available Key-value Store](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) - DeCandia et al., 2007
- [PNUTS: Yahoo!'s Hosted Data Serving Platform](http://scholar.google.com/scholar?q=PNUTS:+Yahoo!'s+Hosted+Data+Serving+Platform) - Cooper et al., 2008
- [The Bayou Architecture: Support for Data Sharing among Mobile Users](http://scholar.google.com/scholar?q=The+Bayou+Architecture%3A+Support+for+Data+Sharing+among+Mobile+Users) - Demers et al. 1994
- [Probabilistically Bound Staleness for Practical Partial Quorums](http://pbs.cs.berkeley.edu/pbs-vldb2012.pdf) - Bailis et al., 2012
- [Eventual Consistency Today: Limitations, Extensions, and Beyond](https://queue.acm.org/detail.cfm?id=2462076) - Bailis & Ghodsi, 2013
- [Optimistic replication](http://www.ysaito.com/survey.pdf) - Saito & Shapiro, 2005
